{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42fe5489",
   "metadata": {},
   "source": [
    "# character identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e3eae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.6.0+cu126\n",
      "12.6\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())                     # True\n",
    "print(torch.version.__version__)                     # Torch version (e.g., 2.6.0)\n",
    "print(torch.version.cuda)                            # CUDA version\n",
    "print(torch.cuda.get_device_name(0))                 # Your GPU name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3695d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Load annotated dataset\n",
    "df = pd.read_csv(\"even_semi_annotated.csv\")\n",
    "\n",
    "# Only keep relevant columns\n",
    "df = df[['story_id', 'judul', 'sentence_id', 'word', 'TYPE2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf93c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 1157\n"
     ]
    }
   ],
   "source": [
    "# --- Count total number of sentences ---\n",
    "\n",
    "n_sentences = df[['story_id', 'sentence_id']].drop_duplicates().shape[0]\n",
    "\n",
    "print(f\"Total number of sentences: {n_sentences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda1e927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of sentences per story: 115.70\n"
     ]
    }
   ],
   "source": [
    "# --- Mean number of sentences per story ---\n",
    "\n",
    "sentences_per_story = df[['story_id', 'sentence_id']].drop_duplicates().groupby('story_id').size()\n",
    "mean_sentences_per_story = sentences_per_story.mean()\n",
    "\n",
    "print(f\"Mean number of sentences per story: {mean_sentences_per_story:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bbfcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to unique integers\n",
    "unique_labels = df['TYPE2'].unique().tolist()\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Create list of sentences (grouped by sentence_id)\n",
    "grouped = df.groupby(['story_id', 'sentence_id'])\n",
    "sentences = []\n",
    "labels = []\n",
    "story_ids = []\n",
    "\n",
    "for (story_id, _), group in grouped:\n",
    "    word_list = group['word'].tolist()\n",
    "    label_list = group['TYPE2'].map(label2id).tolist()\n",
    "    sentences.append(word_list)\n",
    "    labels.append(label_list)\n",
    "    story_ids.append(story_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bec3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HuggingFace dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': sentences,\n",
    "    'ner_tags': labels,\n",
    "    'story_id': story_ids\n",
    "})\n",
    "\n",
    "# Train/test split\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Load tokenizer\n",
    "model_checkpoint = \"cahya/bert-base-indonesian-1.5G\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648367d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], \n",
    "        truncation=True, \n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        new_labels = []\n",
    "        current_label = None\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                new_labels.append(-100)\n",
    "            else:\n",
    "                label = labels[word_idx]\n",
    "                label_name = id2label[label]\n",
    "\n",
    "                # Start of a new word\n",
    "                if word_idx != current_label:\n",
    "                    current_label = word_idx\n",
    "                    new_labels.append(label)\n",
    "                # Continuation of the same word\n",
    "                else:\n",
    "                    # Convert B-PER to I-PER for subwords\n",
    "                    if label_name == \"B-PER\":\n",
    "                        new_labels.append(label2id[\"I-PER\"])\n",
    "                    else:\n",
    "                        new_labels.append(label)\n",
    "\n",
    "        all_labels.append(new_labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50658d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/925 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 925/925 [00:00<00:00, 15421.28 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232/232 [00:00<00:00, 16977.73 examples/s]\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label2id), id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2a49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for true, pred in zip(labels, predictions):\n",
    "        true_seq = []\n",
    "        pred_seq = []\n",
    "        for t, p in zip(true, pred):\n",
    "            if t != -100:\n",
    "                true_seq.append(id2label[t])\n",
    "                pred_seq.append(id2label[p])\n",
    "        true_labels.append(true_seq)\n",
    "        pred_labels.append(pred_seq)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
    "        \"precision\": precision_score(true_labels, pred_labels),\n",
    "        \"recall\": recall_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce31950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayssa\\AppData\\Local\\Temp\\ipykernel_13876\\2001579131.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019351c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='580' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [580/580 03:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>0.977824</td>\n",
       "      <td>0.847896</td>\n",
       "      <td>0.882155</td>\n",
       "      <td>0.864686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.980126</td>\n",
       "      <td>0.875410</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.887043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.073246</td>\n",
       "      <td>0.978033</td>\n",
       "      <td>0.883162</td>\n",
       "      <td>0.865320</td>\n",
       "      <td>0.874150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.076871</td>\n",
       "      <td>0.981590</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.905724</td>\n",
       "      <td>0.901173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.092698</td>\n",
       "      <td>0.981381</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.898990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.982427</td>\n",
       "      <td>0.895082</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.094119</td>\n",
       "      <td>0.981799</td>\n",
       "      <td>0.889610</td>\n",
       "      <td>0.922559</td>\n",
       "      <td>0.905785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.101568</td>\n",
       "      <td>0.982008</td>\n",
       "      <td>0.891447</td>\n",
       "      <td>0.912458</td>\n",
       "      <td>0.901830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.104151</td>\n",
       "      <td>0.981590</td>\n",
       "      <td>0.879085</td>\n",
       "      <td>0.905724</td>\n",
       "      <td>0.892206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.104119</td>\n",
       "      <td>0.982218</td>\n",
       "      <td>0.879479</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.894040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=580, training_loss=0.03917294784352697, metrics={'train_runtime': 207.3518, 'train_samples_per_second': 44.61, 'train_steps_per_second': 2.797, 'total_flos': 525733286343660.0, 'train_loss': 0.03917294784352697, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6529fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='580' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [580/580 03:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.078114</td>\n",
       "      <td>0.974005</td>\n",
       "      <td>0.851441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.072988</td>\n",
       "      <td>0.977953</td>\n",
       "      <td>0.884400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.978776</td>\n",
       "      <td>0.886937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.078946</td>\n",
       "      <td>0.982396</td>\n",
       "      <td>0.916951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.085543</td>\n",
       "      <td>0.983054</td>\n",
       "      <td>0.915825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.092043</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>0.905077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093117</td>\n",
       "      <td>0.982231</td>\n",
       "      <td>0.907263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.093897</td>\n",
       "      <td>0.982560</td>\n",
       "      <td>0.909497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.094984</td>\n",
       "      <td>0.982396</td>\n",
       "      <td>0.909699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=580, training_loss=0.038465827600709324, metrics={'train_runtime': 209.5451, 'train_samples_per_second': 44.143, 'train_steps_per_second': 2.768, 'total_flos': 489342824583408.0, 'train_loss': 0.038465827600709324, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afb14b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./ner_model\\\\tokenizer_config.json',\n",
       " './ner_model\\\\special_tokens_map.json',\n",
       " './ner_model\\\\vocab.txt',\n",
       " './ner_model\\\\added_tokens.json',\n",
       " './ner_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save final model\n",
    "model.save_pretrained(\"./ner_model\")\n",
    "tokenizer.save_pretrained(\"./ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67475c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story ID: 10\n",
      "Characters: ['- Dayang', 'Anak Raja', 'Ayahandamu', 'Budak', 'Bunda', 'Ibundanya', 'Isterinya', 'Kakandaku', 'Kepala Rumah Tangga', 'Kunal', 'Menteri', 'Naga Sorai', 'Nagai Sori', 'Orang Menteri', 'Pembesar Kerajaannya', 'Pengawal Rombongan', 'Permaisuri', 'Permaisuri Haroharo', 'Permaisurinya', 'Putera Haroharo', 'Puteri', 'Puteri Raja Margolang', 'Puterinya', 'Raja', 'Raja Haroharo', 'Raja Margolang', 'Rakyat', 'Rakyat Raja Margolang', 'Sipakpak Kunal', 'Tamunya', 'Tukang Dayung']\n",
      "\n",
      "Story ID: 87\n",
      "Characters: ['Laki - Laki', 'Laki - Laki Belulusan Ulakh', 'Penduduk Di', 'Sahabat Lain', 'Teman', 'Ular', 'Usun']\n",
      "\n",
      "Story ID: 26\n",
      "Characters: ['Abang', 'Adik Ipar Laki - Lakinya', 'Adik Iparnya', 'Dik', 'Istri', 'Istrinya', 'Nusa', 'Warga']\n",
      "\n",
      "Story ID: 25\n",
      "Characters: ['Anaknya', 'Ayah', 'Beberi', 'Burung', 'Dewi Anjani', 'Doyan Nada', 'Ibunya', 'Limandaru', 'Manusia', 'Orang Tuanya', 'Pertapa', 'Prajuritnya', 'Raksasa']\n",
      "\n",
      "Story ID: 16\n",
      "Characters: ['Anak Semata Wayangnya', 'Ayah', 'Ibu', 'Ibu Tador', 'Ibunya', 'Lelaki', 'Tador', 'Tetangga']\n",
      "\n",
      "Story ID: 109\n",
      "Characters: ['Ayah Siti Sara', 'Ayahnya', 'Ibu', 'Ibu Kandungnya', 'Ibu Tirinya', 'Ibunya', 'Janda', 'Siti Sara', 'Suaminya']\n",
      "\n",
      "Story ID: 7\n",
      "Characters: ['Abang', 'Abang Beradik', 'Abangnya', 'Adik', 'Adiknya', 'Ahmad', 'Anak Muda', 'Anak Perempuan', 'Ayah', 'Ayah Si Ahmad', 'Ayah Wak', 'Ayahanda', 'Ayahmu', 'Ayahnya', 'Bu', 'Burung Merbuk', 'Burung Rajawali', 'Datuk Bendahara', 'Gajah Putih', 'Hamba', 'Ibu', 'Ibu Ahmad', 'Ibumu', 'Ibunya', 'Isterinya', 'Muhammad', 'Orang Orang Sekampung', 'Orang Tua', 'Pak Ahmad', 'Pawang Merbuk', 'Pembantu', 'Pemuda', 'Pengawal', 'Pengawal Istana', 'Pengawal Raja', 'Perdana Menteri', 'Puteri Bungsu', 'Puteri Puterinya', 'Puteri Sulung', 'Raja', 'Rakyat', 'Rakyat Beta', 'Rakyatnya', 'Tuan Puteri', 'Tuanku', 'Wak', 'Wak Pawang', 'Wak Pawang Merbuk']\n",
      "\n",
      "Story ID: 111\n",
      "Characters: ['Anak', 'Anak Muda', 'Anak Raja', 'Anakku', 'Anaknya', 'Anjing', 'Ayah', 'Ayahnya', 'Ibunya', 'Kucing', 'Monyet', 'Orang Tuanya', 'Raja', 'Tikus', 'Tukang Emas', 'Ular']\n",
      "\n",
      "Story ID: 35\n",
      "Characters: ['Abangnya', 'Adiknya', 'Arwah Aulia', 'Aulia', 'Ayah', 'Ayah Banta Seudang', 'Banta Seudang', 'Bapak', 'Gajah Putih', 'Ibunya', 'Imam', 'Kucing', 'Mak Toyo', 'Nek', 'Pakcikmu', 'Puteri', 'Puteri - Puterinya', 'Raja', 'Raja Buta']\n",
      "\n",
      "Story ID: 23\n",
      "Characters: ['Anak', 'Gadis', 'Ibu', 'Ibunya', 'Mak Siyah', 'Siti', 'Suaminya', 'Tek Kanah']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TokenClassificationPipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "# Setup pipeline\n",
    "ner_pipe = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",  # Merge subwords like B-PER + I-PER\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Clean token (remove subword markers like \"##\")\n",
    "def clean_word(word):\n",
    "    return word.replace(\"##\", \"\").strip()\n",
    "\n",
    "# Final character storage\n",
    "storywise_characters = defaultdict(set)\n",
    "\n",
    "# Process each test sentence\n",
    "for story_id, tokens in zip(dataset[\"test\"][\"story_id\"], dataset[\"test\"][\"tokens\"]):\n",
    "    sentence = \" \".join(tokens)\n",
    "    preds = ner_pipe(sentence)\n",
    "\n",
    "    entity_buffer = []\n",
    "    prev_entity_type = None\n",
    "\n",
    "    for pred in preds:\n",
    "        label = pred[\"entity_group\"]\n",
    "        word = clean_word(pred[\"word\"])\n",
    "\n",
    "        if label.startswith(\"PER\"):\n",
    "            # Flush previous entity buffer\n",
    "            if entity_buffer:\n",
    "                name = tokenizer.convert_tokens_to_string(entity_buffer).strip().title()\n",
    "                if name:\n",
    "                    storywise_characters[story_id].add(name)\n",
    "            entity_buffer = [word]\n",
    "        else:\n",
    "            if entity_buffer:\n",
    "                name = tokenizer.convert_tokens_to_string(entity_buffer).strip().title()\n",
    "                if name:\n",
    "                    storywise_characters[story_id].add(name)\n",
    "                entity_buffer = []\n",
    "\n",
    "        prev_entity_type = label\n",
    "\n",
    "    # Final flush\n",
    "    if entity_buffer:\n",
    "        name = tokenizer.convert_tokens_to_string(entity_buffer).strip().title()\n",
    "        if name:\n",
    "            storywise_characters[story_id].add(name)\n",
    "\n",
    "# âœ… Print final result\n",
    "for story, chars in storywise_characters.items():\n",
    "    print(f\"Story ID: {story}\\nCharacters: {sorted(chars)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1423863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>judul</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Sipakpak Kunal Dan Nagai Sori</td>\n",
       "      <td>- Dayang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Sipakpak Kunal Dan Nagai Sori</td>\n",
       "      <td>Anak Raja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Sipakpak Kunal Dan Nagai Sori</td>\n",
       "      <td>Ayahandamu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Sipakpak Kunal Dan Nagai Sori</td>\n",
       "      <td>Budak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Sipakpak Kunal Dan Nagai Sori</td>\n",
       "      <td>Bunda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>23</td>\n",
       "      <td>Rawang Tengkuluk</td>\n",
       "      <td>Ibunya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>23</td>\n",
       "      <td>Rawang Tengkuluk</td>\n",
       "      <td>Mak Siyah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>23</td>\n",
       "      <td>Rawang Tengkuluk</td>\n",
       "      <td>Siti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>23</td>\n",
       "      <td>Rawang Tengkuluk</td>\n",
       "      <td>Suaminya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>23</td>\n",
       "      <td>Rawang Tengkuluk</td>\n",
       "      <td>Tek Kanah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     story_id                          judul   character\n",
       "0          10  Sipakpak Kunal Dan Nagai Sori    - Dayang\n",
       "1          10  Sipakpak Kunal Dan Nagai Sori   Anak Raja\n",
       "2          10  Sipakpak Kunal Dan Nagai Sori  Ayahandamu\n",
       "3          10  Sipakpak Kunal Dan Nagai Sori       Budak\n",
       "4          10  Sipakpak Kunal Dan Nagai Sori       Bunda\n",
       "..        ...                            ...         ...\n",
       "162        23               Rawang Tengkuluk      Ibunya\n",
       "163        23               Rawang Tengkuluk   Mak Siyah\n",
       "164        23               Rawang Tengkuluk        Siti\n",
       "165        23               Rawang Tengkuluk    Suaminya\n",
       "166        23               Rawang Tengkuluk   Tek Kanah\n",
       "\n",
       "[167 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming this mapping exists from earlier\n",
    "story_id_to_title = df.groupby('story_id')['judul'].first().to_dict()\n",
    "\n",
    "# Flatten the results into one row per character\n",
    "char_data_flat = {\n",
    "    \"story_id\": [],\n",
    "    \"judul\": [],\n",
    "    \"character\": []\n",
    "}\n",
    "\n",
    "for story_id, characters in storywise_characters.items():\n",
    "    for character in sorted(characters):\n",
    "        char_data_flat[\"story_id\"].append(story_id)\n",
    "        char_data_flat[\"judul\"].append(story_id_to_title.get(story_id, \"Unknown\"))\n",
    "        char_data_flat[\"character\"].append(character)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_flat = pd.DataFrame(char_data_flat)\n",
    "\n",
    "# Show it\n",
    "df_flat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fb1d4",
   "metadata": {},
   "source": [
    "## comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ab40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ground_truth_characters = defaultdict(list)\n",
    "\n",
    "for story_id, group in df[df['TYPE2'].isin(['B-PER', 'I-PER'])].groupby(['story_id', 'sentence_id']):\n",
    "    current_entity = []\n",
    "    prev_type = None\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        label = row['TYPE2']\n",
    "        word = row['word']\n",
    "\n",
    "        if label == 'B-PER':\n",
    "            if current_entity:\n",
    "                full_name = \" \".join(current_entity).strip().title()\n",
    "                ground_truth_characters[story_id[0]].append(full_name)\n",
    "            current_entity = [word]\n",
    "        elif label == 'I-PER':\n",
    "            if prev_type in ['B-PER', 'I-PER']:\n",
    "                current_entity.append(word)\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    full_name = \" \".join(current_entity).strip().title()\n",
    "                    ground_truth_characters[story_id[0]].append(full_name)\n",
    "                current_entity = []\n",
    "\n",
    "        prev_type = label\n",
    "\n",
    "    # Flush last entity\n",
    "    if current_entity:\n",
    "        full_name = \" \".join(current_entity).strip().title()\n",
    "        ground_truth_characters[story_id[0]].append(full_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4963109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“š Story ID: 7\n",
      "ğŸŸ¢ Ground Truth Characters: ['Abang', 'Abangku', 'Abangnya', 'Adik', 'Adiknya', 'Ahmad', 'Anak Dara', 'Anak Laki Laki', 'Anak Muda', 'Anak Perempuan', 'Ayah', 'Ayahanda', 'Ayahandanya', 'Ayahmu', 'Ayahnya', 'Baginda Raja', 'Bang', 'Bu', 'Burung', 'Burung Kesayangannya', 'Burung Merbuk', 'Burung Merbuknya', 'Burung Rajawali', 'Datuk Bendahara', 'Gajah Gajah', 'Gajah Putih', 'Ibu', 'Ibu Ahmad', 'Ibumu', 'Ibunya', 'Isterinya', 'Istri', 'Mak', 'Mak Inang', 'Merbuk', 'Muhammad', 'Orang Muda', 'Orang Tua', 'Pak Ahmad', 'Pawang Merbuk', 'Pembantu', 'Pembantunya', 'Pemuda', 'Pengawal', 'Pengawal Istana', 'Pengawal Raja', 'Perdana Menteri', 'Permaisuri', 'Puteranya', 'Puteri', 'Puteri Bungsu', 'Puteri Sulung', 'Putri Bungsu', 'Raja', 'Rajawali', 'Rakyat', 'Rakyatnya', 'Suami', 'Tuan Puteri', 'Tuan Puteri Bungsu', 'Wak', 'Wak Pawang', 'Wak Pawang Merbuk', 'Yang Maha Kuasa']\n",
      "ğŸ”µ Predicted Characters:     ['Abang', 'Abang Beradik', 'Abangnya', 'Adik', 'Adiknya', 'Ahmad', 'Anak Muda', 'Anak Perempuan', 'Ayah', 'Ayah Si Ahmad', 'Ayah Wak', 'Ayahanda', 'Ayahmu', 'Ayahnya', 'Bu', 'Burung Merbuk', 'Burung Rajawali', 'Datuk Bendahara', 'Gajah Putih', 'Hamba', 'Ibu', 'Ibu Ahmad', 'Ibumu', 'Ibunya', 'Isterinya', 'Muhammad', 'Orang Orang Sekampung', 'Orang Tua', 'Pak Ahmad', 'Pawang Merbuk', 'Pembantu', 'Pemuda', 'Pengawal', 'Pengawal Istana', 'Pengawal Raja', 'Perdana Menteri', 'Puteri Bungsu', 'Puteri Puterinya', 'Puteri Sulung', 'Raja', 'Rakyat', 'Rakyat Beta', 'Rakyatnya', 'Tuan Puteri', 'Tuanku', 'Wak', 'Wak Pawang', 'Wak Pawang Merbuk']\n",
      "âœ… Matched: ['Abang', 'Abangnya', 'Adik', 'Adiknya', 'Ahmad', 'Anak Muda', 'Anak Perempuan', 'Ayah', 'Ayahanda', 'Ayahmu', 'Ayahnya', 'Bu', 'Burung Merbuk', 'Burung Rajawali', 'Datuk Bendahara', 'Gajah Putih', 'Ibu', 'Ibu Ahmad', 'Ibumu', 'Ibunya', 'Isterinya', 'Muhammad', 'Orang Tua', 'Pak Ahmad', 'Pawang Merbuk', 'Pembantu', 'Pemuda', 'Pengawal', 'Pengawal Istana', 'Pengawal Raja', 'Perdana Menteri', 'Puteri Bungsu', 'Puteri Sulung', 'Raja', 'Rakyat', 'Rakyatnya', 'Tuan Puteri', 'Wak', 'Wak Pawang', 'Wak Pawang Merbuk']\n",
      "âŒ Missed:  ['Abangku', 'Anak Dara', 'Anak Laki Laki', 'Ayahandanya', 'Baginda Raja', 'Bang', 'Burung', 'Burung Kesayangannya', 'Burung Merbuknya', 'Gajah Gajah', 'Istri', 'Mak', 'Mak Inang', 'Merbuk', 'Orang Muda', 'Pembantunya', 'Permaisuri', 'Puteranya', 'Puteri', 'Putri Bungsu', 'Rajawali', 'Suami', 'Tuan Puteri Bungsu', 'Yang Maha Kuasa']\n",
      "ğŸŒ€ Extra:   ['Abang Beradik', 'Ayah Si Ahmad', 'Ayah Wak', 'Hamba', 'Orang Orang Sekampung', 'Puteri Puterinya', 'Rakyat Beta', 'Tuanku']\n",
      "\n",
      "ğŸ“š Story ID: 10\n",
      "ğŸŸ¢ Ground Truth Characters: ['Adiknya', 'Ahli Nujum', 'Anak Raja', 'Anggota Keluarga', 'Anggota Rombongan', 'Anggota-Anggota Keluarga Ayah', 'Ayah', 'Ayahandamu', 'Ayahku', 'Budak', 'Budak Pengawal Rombongan', 'Budak-Budak', 'Budak-Budak Perempuan', 'Bunda', 'Dayang-Dayang', 'Dayang-Dayangnya', 'Dewan Penasihat Raja Margolang', 'Ibu', 'Ibuku', 'Ibundanya', 'Kerabat Raja', 'Kunal', 'Menantu Raja Margolang', 'Menantu Tuanku', 'Menteri', 'Menteri Dalam Negeri', 'Menteri Pertahanan', 'Menteri-Menteri', 'Mertuaku', 'Naga Sorai', 'Nagai Sori', 'Pegawai Istana', 'Pembesar Kerajaan', 'Pembesar Kerajaan Haroharo', 'Pembesar Kerajaannya', 'Pembesar Negara', 'Pembesar Negeri', 'Pembesar-Pembesar Kerajaan', 'Pemuka Daerah-Daerah', 'Penduduk', 'Pengawal', 'Penunjuk Jalan', 'Penyanyi-Penyanyi', 'Perdana Menteri', 'Permaisuri', 'Permaisuri Haroharo', 'Permaisuri Raja Haroharo', 'Permaisuri Raja Margolang', 'Permaisurinya', 'Putera Haroharo', 'Puteranya', 'Puteri', 'Puteri Margolang', 'Puteri Raja', 'Puteri Raja Margolang', 'Puterinya', 'Raja', 'Raja Haroharo', 'Raja Margolang', 'Raja Yang Sangat Berkuasa', 'Rakyat', 'Rakyat Haroharo', 'Rakyat Raja Margolang', 'Sahang Mataniari', 'Sipakpak Kunal', 'Suaminya', 'Tuan Puteri', 'Tuanku', 'Tuanku Syah Alam', 'Tukang Dayung']\n",
      "ğŸ”µ Predicted Characters:     ['- Dayang', 'Anak Raja', 'Ayahandamu', 'Budak', 'Bunda', 'Ibundanya', 'Isterinya', 'Kakandaku', 'Kepala Rumah Tangga', 'Kunal', 'Menteri', 'Naga Sorai', 'Nagai Sori', 'Orang Menteri', 'Pembesar Kerajaannya', 'Pengawal Rombongan', 'Permaisuri', 'Permaisuri Haroharo', 'Permaisurinya', 'Putera Haroharo', 'Puteri', 'Puteri Raja Margolang', 'Puterinya', 'Raja', 'Raja Haroharo', 'Raja Margolang', 'Rakyat', 'Rakyat Raja Margolang', 'Sipakpak Kunal', 'Tamunya', 'Tukang Dayung']\n",
      "âœ… Matched: ['Anak Raja', 'Ayahandamu', 'Budak', 'Bunda', 'Ibundanya', 'Kunal', 'Menteri', 'Naga Sorai', 'Nagai Sori', 'Pembesar Kerajaannya', 'Permaisuri', 'Permaisuri Haroharo', 'Permaisurinya', 'Putera Haroharo', 'Puteri', 'Puteri Raja Margolang', 'Puterinya', 'Raja', 'Raja Haroharo', 'Raja Margolang', 'Rakyat', 'Rakyat Raja Margolang', 'Sipakpak Kunal', 'Tukang Dayung']\n",
      "âŒ Missed:  ['Adiknya', 'Ahli Nujum', 'Anggota Keluarga', 'Anggota Rombongan', 'Anggota-Anggota Keluarga Ayah', 'Ayah', 'Ayahku', 'Budak Pengawal Rombongan', 'Budak-Budak', 'Budak-Budak Perempuan', 'Dayang-Dayang', 'Dayang-Dayangnya', 'Dewan Penasihat Raja Margolang', 'Ibu', 'Ibuku', 'Kerabat Raja', 'Menantu Raja Margolang', 'Menantu Tuanku', 'Menteri Dalam Negeri', 'Menteri Pertahanan', 'Menteri-Menteri', 'Mertuaku', 'Pegawai Istana', 'Pembesar Kerajaan', 'Pembesar Kerajaan Haroharo', 'Pembesar Negara', 'Pembesar Negeri', 'Pembesar-Pembesar Kerajaan', 'Pemuka Daerah-Daerah', 'Penduduk', 'Pengawal', 'Penunjuk Jalan', 'Penyanyi-Penyanyi', 'Perdana Menteri', 'Permaisuri Raja Haroharo', 'Permaisuri Raja Margolang', 'Puteranya', 'Puteri Margolang', 'Puteri Raja', 'Raja Yang Sangat Berkuasa', 'Rakyat Haroharo', 'Sahang Mataniari', 'Suaminya', 'Tuan Puteri', 'Tuanku', 'Tuanku Syah Alam']\n",
      "ğŸŒ€ Extra:   ['- Dayang', 'Isterinya', 'Kakandaku', 'Kepala Rumah Tangga', 'Orang Menteri', 'Pengawal Rombongan', 'Tamunya']\n",
      "\n",
      "ğŸ“š Story ID: 16\n",
      "ğŸŸ¢ Ground Truth Characters: ['Anak', 'Anak Semata Wayangnya', 'Ayah', 'Ayah Tador', 'Cucu', 'Ibu', 'Ibu Tador', 'Ibunya', 'Kakek', 'Nenek', 'Nenek Tador', 'Neneknya', 'Orang Tua Tador', 'Orang Tuanya', 'Suami', 'Tador', 'Tetangga', 'Warga', 'Warga Kampung']\n",
      "ğŸ”µ Predicted Characters:     ['Anak Semata Wayangnya', 'Ayah', 'Ibu', 'Ibu Tador', 'Ibunya', 'Lelaki', 'Tador', 'Tetangga']\n",
      "âœ… Matched: ['Anak Semata Wayangnya', 'Ayah', 'Ibu', 'Ibu Tador', 'Ibunya', 'Tador', 'Tetangga']\n",
      "âŒ Missed:  ['Anak', 'Ayah Tador', 'Cucu', 'Kakek', 'Nenek', 'Nenek Tador', 'Neneknya', 'Orang Tua Tador', 'Orang Tuanya', 'Suami', 'Warga', 'Warga Kampung']\n",
      "ğŸŒ€ Extra:   ['Lelaki']\n",
      "\n",
      "ğŸ“š Story ID: 23\n",
      "ğŸŸ¢ Ground Truth Characters: ['Anak', 'Anak Gadis', 'Anak Gadisnya', 'Anak Hamba', 'Anak Seorang Janda Miskin', 'Anak Yang Pemalas', 'Anaknya', 'Ayah', 'Bu', 'Bujang', 'Gadis', 'Ibu', 'Ibunya', 'Mak Siyah', 'Nak', 'Orang Kaya Di Kampung', 'Orang Tua', 'Penduduk', 'Seorang Perempuan', 'Siti', 'Suaminya', 'Tek Kanah', 'Tuhan']\n",
      "ğŸ”µ Predicted Characters:     ['Anak', 'Gadis', 'Ibu', 'Ibunya', 'Mak Siyah', 'Siti', 'Suaminya', 'Tek Kanah']\n",
      "âœ… Matched: ['Anak', 'Gadis', 'Ibu', 'Ibunya', 'Mak Siyah', 'Siti', 'Suaminya', 'Tek Kanah']\n",
      "âŒ Missed:  ['Anak Gadis', 'Anak Gadisnya', 'Anak Hamba', 'Anak Seorang Janda Miskin', 'Anak Yang Pemalas', 'Anaknya', 'Ayah', 'Bu', 'Bujang', 'Nak', 'Orang Kaya Di Kampung', 'Orang Tua', 'Penduduk', 'Seorang Perempuan', 'Tuhan']\n",
      "ğŸŒ€ Extra:   []\n",
      "\n",
      "ğŸ“š Story ID: 25\n",
      "ğŸŸ¢ Ground Truth Characters: ['Anak', 'Anak Kecil', 'Anak Manusia', 'Anak Semata Wayangnya', 'Anaknya', 'Ayah', 'Ayahnya', 'Bayi Ajaib', 'Bayi Laki-Laki Yang Ajaib', 'Beberi', 'Bu', 'Burung', 'Burung Peliharaannya', 'Dewi Anjani', 'Doyan', 'Doyan Nada', 'Ibu', 'Ibunya', 'Istri', 'Istri Sang Kepala Suku', 'Kakek Tuan Putri', 'Kedua Orang Tua', 'Kedua Orang Tuanya', 'Kepala Suku', 'Kesepuluh Pasangan Suami Istri', 'Limandaru', 'Nak', 'Orang', 'Orang-Orang', 'Patih', 'Patih Songan', 'Penduduk Desa', 'Pengikutnya', 'Pertapa', 'Prajurit Dari Bangsa Jin', 'Prajuritnya', 'Raksasa', 'Ratu Jin', 'Sakti Mandraguna', 'Sepuluh Pasang Suami Istri', 'Sigar Penjalin', 'Suaminya', 'Tameng Muter', 'Tuan Putri', 'Tuannya', 'Yah']\n",
      "ğŸ”µ Predicted Characters:     ['Anaknya', 'Ayah', 'Beberi', 'Burung', 'Dewi Anjani', 'Doyan Nada', 'Ibunya', 'Limandaru', 'Manusia', 'Orang Tuanya', 'Pertapa', 'Prajuritnya', 'Raksasa']\n",
      "âœ… Matched: ['Anaknya', 'Ayah', 'Beberi', 'Burung', 'Dewi Anjani', 'Doyan Nada', 'Ibunya', 'Limandaru', 'Pertapa', 'Prajuritnya', 'Raksasa']\n",
      "âŒ Missed:  ['Anak', 'Anak Kecil', 'Anak Manusia', 'Anak Semata Wayangnya', 'Ayahnya', 'Bayi Ajaib', 'Bayi Laki-Laki Yang Ajaib', 'Bu', 'Burung Peliharaannya', 'Doyan', 'Ibu', 'Istri', 'Istri Sang Kepala Suku', 'Kakek Tuan Putri', 'Kedua Orang Tua', 'Kedua Orang Tuanya', 'Kepala Suku', 'Kesepuluh Pasangan Suami Istri', 'Nak', 'Orang', 'Orang-Orang', 'Patih', 'Patih Songan', 'Penduduk Desa', 'Pengikutnya', 'Prajurit Dari Bangsa Jin', 'Ratu Jin', 'Sakti Mandraguna', 'Sepuluh Pasang Suami Istri', 'Sigar Penjalin', 'Suaminya', 'Tameng Muter', 'Tuan Putri', 'Tuannya', 'Yah']\n",
      "ğŸŒ€ Extra:   ['Manusia', 'Orang Tuanya']\n",
      "\n",
      "ğŸ“š Story ID: 26\n",
      "ğŸŸ¢ Ground Truth Characters: ['Abang', 'Adik', 'Adik Ipar Laki-Lakinya', 'Adik Ipar Nusa', 'Adik Iparnya', 'Bang', 'Dik', 'Ikan', 'Ikan Jelawat', 'Ikan Saluang', 'Ikan-Ikan', 'Istri', 'Istri Nusa', 'Istrinya', 'Naga', 'Naga Besar', 'Naga Nusa', 'Nusa', 'Orang Warga', 'Saudara-Saudara', 'Suaminya', 'Tuan', 'Tuan Naga', 'Tuhan', 'Ular Naga', 'Warga']\n",
      "ğŸ”µ Predicted Characters:     ['Abang', 'Adik Ipar Laki - Lakinya', 'Adik Iparnya', 'Dik', 'Istri', 'Istrinya', 'Nusa', 'Warga']\n",
      "âœ… Matched: ['Abang', 'Adik Iparnya', 'Dik', 'Istri', 'Istrinya', 'Nusa', 'Warga']\n",
      "âŒ Missed:  ['Adik', 'Adik Ipar Laki-Lakinya', 'Adik Ipar Nusa', 'Bang', 'Ikan', 'Ikan Jelawat', 'Ikan Saluang', 'Ikan-Ikan', 'Istri Nusa', 'Naga', 'Naga Besar', 'Naga Nusa', 'Orang Warga', 'Saudara-Saudara', 'Suaminya', 'Tuan', 'Tuan Naga', 'Tuhan', 'Ular Naga']\n",
      "ğŸŒ€ Extra:   ['Adik Ipar Laki - Lakinya']\n",
      "\n",
      "ğŸ“š Story ID: 35\n",
      "ğŸŸ¢ Ground Truth Characters: ['7 Orang Puteri', 'Abangnya', 'Adik Kandungnya', 'Adik Saya', 'Adikmu', 'Adiknya', 'Anak Raja', 'Anak-Anaknya', 'Anakku', 'Arwah Aulia', 'Arwah-Arwah Para Aulia Allah', 'Aulia', 'Ayah', 'Ayah Banta Seudang', 'Ayahku', 'Ayahnya', 'Banta', 'Banta Seudang', 'Bapak', 'Bungsu', 'Gajah', 'Gajah Putih', 'Gajah Putihnya', 'Ibu Banta Seudang', 'Ibunya', 'Imam', 'Imam Sembahyang', 'Isterinya', 'Jin Pari', 'Kakak-Kakaknya', 'Keenam Orang Kakaknya', 'Ketujuh Orang Puteri Raja', 'Kucing', 'Mak', 'Mak Toyo', 'Nek', 'Nek Toyo', 'Nenek', 'Nenek Tua', 'Orang', 'Orang Yang Sembahyang', 'Pakcik', 'Pakcikmu', 'Penjaganya', 'Puteri', 'Puteri Bungsu', 'Puteri Raja', 'Puteri Yang Paling Bungsu', 'Puteri-Puterinya', 'Puteri-Puterinya Raja', 'Puterinya', 'Raja', 'Raja Buta', 'Serombongan Puteri', 'Tuan Puteri', 'Wanita Tua', 'Yah']\n",
      "ğŸ”µ Predicted Characters:     ['Abangnya', 'Adiknya', 'Arwah Aulia', 'Aulia', 'Ayah', 'Ayah Banta Seudang', 'Banta Seudang', 'Bapak', 'Gajah Putih', 'Ibunya', 'Imam', 'Kucing', 'Mak Toyo', 'Nek', 'Pakcikmu', 'Puteri', 'Puteri - Puterinya', 'Raja', 'Raja Buta']\n",
      "âœ… Matched: ['Abangnya', 'Adiknya', 'Arwah Aulia', 'Aulia', 'Ayah', 'Ayah Banta Seudang', 'Banta Seudang', 'Bapak', 'Gajah Putih', 'Ibunya', 'Imam', 'Kucing', 'Mak Toyo', 'Nek', 'Pakcikmu', 'Puteri', 'Raja', 'Raja Buta']\n",
      "âŒ Missed:  ['7 Orang Puteri', 'Adik Kandungnya', 'Adik Saya', 'Adikmu', 'Anak Raja', 'Anak-Anaknya', 'Anakku', 'Arwah-Arwah Para Aulia Allah', 'Ayahku', 'Ayahnya', 'Banta', 'Bungsu', 'Gajah', 'Gajah Putihnya', 'Ibu Banta Seudang', 'Imam Sembahyang', 'Isterinya', 'Jin Pari', 'Kakak-Kakaknya', 'Keenam Orang Kakaknya', 'Ketujuh Orang Puteri Raja', 'Mak', 'Nek Toyo', 'Nenek', 'Nenek Tua', 'Orang', 'Orang Yang Sembahyang', 'Pakcik', 'Penjaganya', 'Puteri Bungsu', 'Puteri Raja', 'Puteri Yang Paling Bungsu', 'Puteri-Puterinya', 'Puteri-Puterinya Raja', 'Puterinya', 'Serombongan Puteri', 'Tuan Puteri', 'Wanita Tua', 'Yah']\n",
      "ğŸŒ€ Extra:   ['Puteri - Puterinya']\n",
      "\n",
      "ğŸ“š Story ID: 87\n",
      "ğŸŸ¢ Ground Truth Characters: ['Hewan Melata', 'Laki-Laki', 'Laki-Laki Belulusan Ulakh', 'Orang Didusun', 'Orang-Orang Sedusun', 'Penduduk', 'Penduduk Desa', 'Penduduk Dusun', 'Puyang', 'Seorang Sesepuh Dusun', 'Sesepuh', 'Sesepuh Dusun', 'Teman Sedusun', 'Teman Sepermainannya', 'Teman Temannya', 'Teman-Temannya', 'Tetangganya', 'Ular', 'Warga']\n",
      "ğŸ”µ Predicted Characters:     ['Laki - Laki', 'Laki - Laki Belulusan Ulakh', 'Penduduk Di', 'Sahabat Lain', 'Teman', 'Ular', 'Usun']\n",
      "âœ… Matched: ['Ular']\n",
      "âŒ Missed:  ['Hewan Melata', 'Laki-Laki', 'Laki-Laki Belulusan Ulakh', 'Orang Didusun', 'Orang-Orang Sedusun', 'Penduduk', 'Penduduk Desa', 'Penduduk Dusun', 'Puyang', 'Seorang Sesepuh Dusun', 'Sesepuh', 'Sesepuh Dusun', 'Teman Sedusun', 'Teman Sepermainannya', 'Teman Temannya', 'Teman-Temannya', 'Tetangganya', 'Warga']\n",
      "ğŸŒ€ Extra:   ['Laki - Laki', 'Laki - Laki Belulusan Ulakh', 'Penduduk Di', 'Sahabat Lain', 'Teman', 'Usun']\n",
      "\n",
      "ğŸ“š Story ID: 109\n",
      "ğŸŸ¢ Ground Truth Characters: ['Anak Tunggal', 'Anak Yang Dibawa Ibu Tirinya', 'Anak Yang Masih Kecil', 'Anakku', 'Anaknya', 'Ayah Siti Sara', 'Ayahmu', 'Ayahnya', 'Ibu', 'Ibu Siti Sara', 'Ibu Tiri', 'Ibu Tirinya', 'Ibumu', 'Ibunya', 'Isterinya', 'Janda', 'Orang', 'Orang Lain', 'Papa', 'Semua Orang Di Kampung', 'Siti', 'Siti Sara', 'Suaminya', 'Tuhan']\n",
      "ğŸ”µ Predicted Characters:     ['Ayah Siti Sara', 'Ayahnya', 'Ibu', 'Ibu Kandungnya', 'Ibu Tirinya', 'Ibunya', 'Janda', 'Siti Sara', 'Suaminya']\n",
      "âœ… Matched: ['Ayah Siti Sara', 'Ayahnya', 'Ibu', 'Ibu Tirinya', 'Ibunya', 'Janda', 'Siti Sara', 'Suaminya']\n",
      "âŒ Missed:  ['Anak Tunggal', 'Anak Yang Dibawa Ibu Tirinya', 'Anak Yang Masih Kecil', 'Anakku', 'Anaknya', 'Ayahmu', 'Ibu Siti Sara', 'Ibu Tiri', 'Ibumu', 'Isterinya', 'Orang', 'Orang Lain', 'Papa', 'Semua Orang Di Kampung', 'Siti', 'Tuhan']\n",
      "ğŸŒ€ Extra:   ['Ibu Kandungnya']\n",
      "\n",
      "ğŸ“š Story ID: 111\n",
      "ğŸŸ¢ Ground Truth Characters: ['Anak', 'Anak Muda', 'Anak Raja', 'Anak Tunggal Raja', 'Anak-Anak', 'Anakku', 'Anaknya', 'Anjing', 'Anjinglah', 'Ayah', 'Ayahnya', 'Bundanya', 'Burung', 'Ibunya', 'Istri Raja', 'Istrinya', 'Kucing', 'Monyet', 'Orang', 'Orang-Orang', 'Raja', 'Rakyat', 'Rakyatku', 'Rakyatnya', 'Segerombolan Orang', 'Tikus', 'Tuhan', 'Tuhan Yang Maha Esa', 'Tukang Emas', 'Ular', 'Ular Besar']\n",
      "ğŸ”µ Predicted Characters:     ['Anak', 'Anak Muda', 'Anak Raja', 'Anakku', 'Anaknya', 'Anjing', 'Ayah', 'Ayahnya', 'Ibunya', 'Kucing', 'Monyet', 'Orang Tuanya', 'Raja', 'Tikus', 'Tukang Emas', 'Ular']\n",
      "âœ… Matched: ['Anak', 'Anak Muda', 'Anak Raja', 'Anakku', 'Anaknya', 'Anjing', 'Ayah', 'Ayahnya', 'Ibunya', 'Kucing', 'Monyet', 'Raja', 'Tikus', 'Tukang Emas', 'Ular']\n",
      "âŒ Missed:  ['Anak Tunggal Raja', 'Anak-Anak', 'Anjinglah', 'Bundanya', 'Burung', 'Istri Raja', 'Istrinya', 'Orang', 'Orang-Orang', 'Rakyat', 'Rakyatku', 'Rakyatnya', 'Segerombolan Orang', 'Tuhan', 'Tuhan Yang Maha Esa', 'Ular Besar']\n",
      "ğŸŒ€ Extra:   ['Orang Tuanya']\n"
     ]
    }
   ],
   "source": [
    "for story_id in sorted(set(list(ground_truth_characters.keys()) + list(storywise_characters.keys()))):\n",
    "    gt_set = set(ground_truth_characters.get(story_id, []))\n",
    "    pred_set = set(storywise_characters.get(story_id, []))\n",
    "    \n",
    "    print(f\"\\nğŸ“š Story ID: {story_id}\")\n",
    "    print(f\"ğŸŸ¢ Ground Truth Characters: {sorted(gt_set)}\")\n",
    "    print(f\"ğŸ”µ Predicted Characters:     {sorted(pred_set)}\")\n",
    "    \n",
    "    matched = gt_set & pred_set\n",
    "    missed = gt_set - pred_set\n",
    "    extra = pred_set - gt_set\n",
    "\n",
    "    print(f\"âœ… Matched: {sorted(matched)}\")\n",
    "    print(f\"âŒ Missed:  {sorted(missed)}\")\n",
    "    print(f\"ğŸŒ€ Extra:   {sorted(extra)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d963d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def precision_recall_f1(y_true, y_pred):\n",
    "    true_set = set(y_true)\n",
    "    pred_set = set(y_pred)\n",
    "    intersection = true_set & pred_set\n",
    "\n",
    "    precision = len(intersection) / len(pred_set) if pred_set else 0.0\n",
    "    recall = len(intersection) / len(true_set) if true_set else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2596499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   story_id                          judul  ground_truth  predicted  matched  \\\n",
      "0         7             Tuah Burung Merbak           538         48       40   \n",
      "1        10  Sipakpak Kunal Dan Nagai Sori           217         31       24   \n",
      "2        16           Asal Usul Laut Tador            93          8        7   \n",
      "3        23               Rawang Tengkuluk           170          8        8   \n",
      "4        25               Kisah Doyan Nada           164         13       11   \n",
      "5        26           Asal Mula Pulau Nusa           139          8        7   \n",
      "6        35                  Banta Seudang           191         19       18   \n",
      "7        87                  Tanjung Siman            38          7        1   \n",
      "8       109                        Ine Ude           155          9        8   \n",
      "9       111                 Mentiko Betuah           173         16       15   \n",
      "\n",
      "   precision  recall  f1_score  \n",
      "0      0.833   0.625     0.714  \n",
      "1      0.774   0.343     0.475  \n",
      "2      0.875   0.368     0.519  \n",
      "3      1.000   0.348     0.516  \n",
      "4      0.846   0.239     0.373  \n",
      "5      0.875   0.269     0.412  \n",
      "6      0.947   0.316     0.474  \n",
      "7      0.143   0.053     0.077  \n",
      "8      0.889   0.333     0.485  \n",
      "9      0.938   0.484     0.638  \n"
     ]
    }
   ],
   "source": [
    "eval_data = {\n",
    "    \"story_id\": [],\n",
    "    \"judul\": [],\n",
    "    \"ground_truth\": [],\n",
    "    \"predicted\": [],\n",
    "    \"matched\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": []\n",
    "}\n",
    "\n",
    "for story_id in sorted(set(ground_truth_characters) | set(storywise_characters)):\n",
    "    gt = ground_truth_characters.get(story_id, [])\n",
    "    pred = list(storywise_characters.get(story_id, set()))\n",
    "    matched = list(set(gt) & set(pred))\n",
    "\n",
    "    p, r, f1 = precision_recall_f1(gt, pred)\n",
    "\n",
    "    eval_data[\"story_id\"].append(story_id)\n",
    "    eval_data[\"judul\"].append(story_id_to_title.get(story_id, \"Unknown\"))\n",
    "    eval_data[\"ground_truth\"].append(len(gt))\n",
    "    eval_data[\"predicted\"].append(len(pred))\n",
    "    eval_data[\"matched\"].append(len(matched))\n",
    "    eval_data[\"precision\"].append(round(p, 3))\n",
    "    eval_data[\"recall\"].append(round(r, 3))\n",
    "    eval_data[\"f1_score\"].append(round(f1, 3))\n",
    "\n",
    "df_eval = pd.DataFrame(eval_data)\n",
    "print(df_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7869631a",
   "metadata": {},
   "source": [
    "# pseudo-labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff076cec",
   "metadata": {},
   "source": [
    "## pseudo labelling round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ecd5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 7706 rows of sentence-level character mentions.\n",
      "ğŸ“Š Saved confidence stats for 222 stories.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load and group the unlabeled data\n",
    "df_unlabeled = pd.read_csv(\"../preprocessing/cerita_rakyat_tokenized_clean.csv\")\n",
    "\n",
    "# Group into sentences\n",
    "grouped = df_unlabeled.groupby(['story_id', 'sentence_id'])\n",
    "sentence_map = []\n",
    "for (story_id, sentence_id), group in grouped:\n",
    "    words = group['word'].astype(str).tolist()\n",
    "    sentence_map.append((story_id, sentence_id, words))\n",
    "\n",
    "# Load fine-tuned model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model\")\n",
    "\n",
    "pseudo_pipe = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Store sentence-level characters\n",
    "sentence_character_data = []\n",
    "\n",
    "# Store confidence scores by story\n",
    "story_confidence_data = defaultdict(list)\n",
    "\n",
    "for story_id, sentence_id, tokens in sentence_map:\n",
    "    sentence_text = \" \".join(tokens)\n",
    "    preds = pseudo_pipe(sentence_text)\n",
    "\n",
    "    char_names = set()\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\" and pred[\"score\"] >= 0.96:\n",
    "            char_name = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "            if char_name and len(char_name) > 1 and not char_name.isspace():\n",
    "                char_names.add(char_name)\n",
    "                story_confidence_data[story_id].append(pred[\"score\"])\n",
    "\n",
    "    if char_names:\n",
    "        sentence_character_data.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(char_names)\n",
    "        })\n",
    "\n",
    "# Save sentence-level character mentions\n",
    "df_chars = pd.DataFrame(sentence_character_data)\n",
    "df_chars.to_csv(\"pseudo_characters_by_sentence.csv\", index=False)\n",
    "\n",
    "# Build story-level confidence summary\n",
    "story_conf_stats = []\n",
    "for story_id, confs in story_confidence_data.items():\n",
    "    story_conf_stats.append({\n",
    "        \"story_id\": story_id,\n",
    "        \"avg_confidence\": round(sum(confs) / len(confs), 4),\n",
    "        \"min_confidence\": round(min(confs), 4),\n",
    "        \"max_confidence\": round(max(confs), 4),\n",
    "        \"mention_count\": len(confs)\n",
    "    })\n",
    "\n",
    "df_conf = pd.DataFrame(story_conf_stats).sort_values(\"avg_confidence\", ascending=False)\n",
    "df_conf.to_csv(\"confidence_per_story.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Saved {len(df_chars)} rows of sentence-level character mentions.\")\n",
    "print(f\"ğŸ“Š Saved confidence stats for {len(df_conf)} stories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e61bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– Number of unique stories with character predictions: 222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sentence-level character data\n",
    "df = pd.read_csv(\"pseudo_characters_by_sentence.csv\")\n",
    "\n",
    "# Count unique story IDs\n",
    "num_stories = df[\"story_id\"].nunique()\n",
    "\n",
    "print(f\"ğŸ“– Number of unique stories with character predictions: {num_stories}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d973abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… High-confidence pseudo-labeled sentences: 7905\n",
      "ğŸ”„ Sentences saved for next pseudo-labeling round: 3378\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Parameters ===\n",
    "confidence_threshold = 0.95  # Set your threshold (95%)\n",
    "\n",
    "# === Step 1: Load Unlabeled Data ===\n",
    "df_unlabeled = pd.read_csv(\"../preprocessing/cerita_rakyat_tokenized_clean.csv\")\n",
    "\n",
    "# Group into sentences\n",
    "grouped = df_unlabeled.groupby(['story_id', 'sentence_id'])\n",
    "sentence_map = []\n",
    "for (story_id, sentence_id), group in grouped:\n",
    "    words = group['word'].astype(str).tolist()\n",
    "    sentence_map.append((story_id, sentence_id, words))\n",
    "\n",
    "# === Step 2: Load Model ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model\")\n",
    "\n",
    "pseudo_pipe = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 3: Pseudo-Labeling ===\n",
    "high_conf_pseudo_labels = []  # Will be used to augment training data\n",
    "leftover_sentences = []       # Sentences that need reprocessing later\n",
    "\n",
    "for story_id, sentence_id, tokens in sentence_map:\n",
    "    sentence_text = \" \".join(tokens)\n",
    "    preds = pseudo_pipe(sentence_text)\n",
    "\n",
    "    char_names = []\n",
    "    char_confidences = []\n",
    "    low_conf = False\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            if pred[\"score\"] >= confidence_threshold:\n",
    "                char_name = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "                if char_name and len(char_name) > 1 and not char_name.isspace():\n",
    "                    char_names.append(char_name)\n",
    "                    char_confidences.append(round(pred[\"score\"], 4))\n",
    "            else:\n",
    "                low_conf = True\n",
    "\n",
    "    if char_names:\n",
    "        high_conf_pseudo_labels.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(set(char_names)),\n",
    "            \"confidences\": char_confidences\n",
    "        })\n",
    "\n",
    "    # If any low confidence detected, add sentence to leftovers\n",
    "    if low_conf:\n",
    "        leftover_sentences.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "# === Step 4: Save Results ===\n",
    "\n",
    "# Save high confidence pseudo labels\n",
    "df_high_conf = pd.DataFrame(high_conf_pseudo_labels)\n",
    "df_high_conf.to_csv(\"pseudo_characters_high_confidence.csv\", index=False)\n",
    "\n",
    "# Save leftover sentences for next round\n",
    "df_leftover = pd.DataFrame(leftover_sentences)\n",
    "df_leftover.to_csv(\"leftover_sentences_for_next_round.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… High-confidence pseudo-labeled sentences: {len(df_high_conf)}\")\n",
    "print(f\"ğŸ”„ Sentences saved for next pseudo-labeling round: {len(df_leftover)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aacbdba",
   "metadata": {},
   "source": [
    "## psedo labelling round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8669e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original sentence-tokenized data\n",
    "df_tokens = pd.read_csv(\"../preprocessing/cerita_rakyat_tokenized_clean.csv\")\n",
    "\n",
    "# Load sentence-level pseudo labels\n",
    "df_pseudo = pd.read_csv(\"pseudo_characters_high_confidence.csv\")\n",
    "df_pseudo['characters'] = df_pseudo['characters'].apply(eval)  # Convert from string to list\n",
    "\n",
    "# Merge pseudo labels with the token-level data\n",
    "joined_ids = set(zip(df_pseudo['story_id'], df_pseudo['sentence_id']))\n",
    "df_matched = df_tokens[df_tokens.apply(lambda row: (row['story_id'], row['sentence_id']) in joined_ids, axis=1)].copy()\n",
    "\n",
    "# Merge character labels into each sentence row\n",
    "df_merged = df_matched.merge(df_pseudo[['story_id', 'sentence_id', 'characters']], on=['story_id', 'sentence_id'], how='left')\n",
    "\n",
    "# Function to assign B-PER / I-PER / O\n",
    "def label_token(word, char_list):\n",
    "    word = str(word).lower()  # <- force word to be string first\n",
    "    for char in char_list:\n",
    "        char_tokens = char.lower().split()\n",
    "        if word == char_tokens[0]:\n",
    "            return 'B-PER' if len(char_tokens) == 1 else 'B-PER'\n",
    "        elif word in char_tokens:\n",
    "            return 'I-PER'\n",
    "    return 'O'\n",
    "\n",
    "# Apply labeling\n",
    "df_merged['TYPE2'] = df_merged.apply(lambda row: label_token(row['word'], row['characters']), axis=1)\n",
    "\n",
    "# Drop extras\n",
    "df_pseudo_labeled = df_merged[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Save as pseudo training data\n",
    "df_pseudo_labeled.to_csv(\"pseudo_word_level_labeled_v1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f5e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original manually labeled dataset\n",
    "df_manual = pd.read_csv(\"even_semi_annotated.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Load pseudo-labeled data\n",
    "df_pseudo = pd.read_csv(\"pseudo_word_level_labeled_v1.csv\")\n",
    "\n",
    "# Combine both\n",
    "df_train = pd.concat([df_manual, df_pseudo], ignore_index=True)\n",
    "\n",
    "# Save final training set\n",
    "df_train.to_csv(\"training_data_for_model_v2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0360fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/6817 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6817/6817 [00:00<00:00, 13452.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1705/1705 [00:00<00:00, 22336.82 examples/s]\n",
      "C:\\Users\\rayssa\\AppData\\Local\\Temp\\ipykernel_51536\\437296244.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4270' max='4270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4270/4270 08:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.074433</td>\n",
       "      <td>0.867597</td>\n",
       "      <td>0.927267</td>\n",
       "      <td>0.896440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>0.914024</td>\n",
       "      <td>0.912355</td>\n",
       "      <td>0.913189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.078789</td>\n",
       "      <td>0.889567</td>\n",
       "      <td>0.931528</td>\n",
       "      <td>0.910064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.093686</td>\n",
       "      <td>0.907757</td>\n",
       "      <td>0.922398</td>\n",
       "      <td>0.915019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.095040</td>\n",
       "      <td>0.909861</td>\n",
       "      <td>0.915399</td>\n",
       "      <td>0.912621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.104345</td>\n",
       "      <td>0.908434</td>\n",
       "      <td>0.917833</td>\n",
       "      <td>0.913109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.121911</td>\n",
       "      <td>0.907835</td>\n",
       "      <td>0.920268</td>\n",
       "      <td>0.914009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.120726</td>\n",
       "      <td>0.918268</td>\n",
       "      <td>0.916312</td>\n",
       "      <td>0.917289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.128447</td>\n",
       "      <td>0.915285</td>\n",
       "      <td>0.923920</td>\n",
       "      <td>0.919582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.134376</td>\n",
       "      <td>0.910998</td>\n",
       "      <td>0.925137</td>\n",
       "      <td>0.918013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: i-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training complete! Model saved at ./ner_model_v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# === Step 1: Load combined dataset ===\n",
    "df = pd.read_csv(\"training_data_for_model_v2.csv\")\n",
    "df = df[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Force all words to be string and no NaN\n",
    "df['word'] = df['word'].fillna('').astype(str)\n",
    "\n",
    "# Build label mappings\n",
    "labels = sorted(df['TYPE2'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Assign token-level fields\n",
    "df['ner_tags'] = df['TYPE2'].map(label2id)\n",
    "df = df[['story_id', 'sentence_id', 'word', 'ner_tags']]\n",
    "\n",
    "# === Step 2: Group by sentences ===\n",
    "grouped = df.groupby(['story_id', 'sentence_id'])\n",
    "sentences = []\n",
    "tags = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    sentences.append(group['word'].tolist())\n",
    "    tags.append(group['ner_tags'].tolist())\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': sentences,\n",
    "    'ner_tags': tags\n",
    "})\n",
    "\n",
    "\n",
    "# === Step 3: Train/test split ===\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# === Step 4: Tokenizer and Model ===\n",
    "model_checkpoint = \"cahya/bert-base-indonesian-1.5G\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# === Step 5: Tokenize and Align Labels ===\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# === Step 6: Metric computation ===\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    true_labels = [[id2label[label] for label in sent if label != -100] for sent in labels]\n",
    "    true_preds = [[id2label[pred] for (pred, label) in zip(sent_pred, sent_label) if label != -100] for sent_pred, sent_label in zip(preds, labels)]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }\n",
    "\n",
    "# === Step 7: Training Arguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model_v2\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs_v2\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# === Step 8: Trainer Setup ===\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === Step 9: Train ===\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(\"./ner_model_v2\")\n",
    "tokenizer.save_pretrained(\"./ner_model_v2\")\n",
    "\n",
    "print(\"âœ… Training complete! Model saved at ./ner_model_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda84eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Round 2 pseudo-labeled sentences: 2842\n",
      "ğŸ”„ Still left for round 3: 367\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# === Step 1: Load model v2 ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model_v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model_v2\")\n",
    "\n",
    "pipeline = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 2: Load leftovers ===\n",
    "df_leftover = pd.read_csv(\"leftover_sentences_for_next_round.csv\")\n",
    "df_leftover['tokens'] = df_leftover['tokens'].apply(eval)  # Convert from string to list\n",
    "\n",
    "# === Step 3: Pseudo-labeling round 2 ===\n",
    "high_conf_pseudo_labels = []\n",
    "still_low_conf = []\n",
    "\n",
    "confidence_threshold = 0.95\n",
    "\n",
    "for _, row in df_leftover.iterrows():\n",
    "    story_id = row['story_id']\n",
    "    sentence_id = row['sentence_id']\n",
    "    tokens = row['tokens']\n",
    "    sentence = \" \".join(tokens)\n",
    "\n",
    "    preds = pipeline(sentence)\n",
    "\n",
    "    char_names = []\n",
    "    confidences = []\n",
    "    low_conf = False\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            score = pred[\"score\"]\n",
    "            word = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "\n",
    "            if score >= confidence_threshold:\n",
    "                if word and len(word) > 1 and not word.isspace():\n",
    "                    char_names.append(word)\n",
    "                    confidences.append(round(score, 4))\n",
    "            else:\n",
    "                low_conf = True\n",
    "\n",
    "    if char_names:\n",
    "        high_conf_pseudo_labels.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(set(char_names)),\n",
    "            \"confidences\": confidences\n",
    "        })\n",
    "\n",
    "    if low_conf:\n",
    "        still_low_conf.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "# === Step 4: Save outputs ===\n",
    "pd.DataFrame(high_conf_pseudo_labels).to_csv(\"pseudo_characters_round2.csv\", index=False)\n",
    "pd.DataFrame(still_low_conf).to_csv(\"leftover_sentences_for_next_round2.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Round 2 pseudo-labeled sentences: {len(high_conf_pseudo_labels)}\")\n",
    "print(f\"ğŸ”„ Still left for round 3: {len(still_low_conf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437e0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total pseudo-labeled sentences after round 2: 9013\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both rounds\n",
    "df_r1 = pd.read_csv(\"pseudo_characters_high_confidence.csv\")\n",
    "df_r2 = pd.read_csv(\"pseudo_characters_round2.csv\")\n",
    "\n",
    "# Convert character/confidences to lists if needed\n",
    "df_r1['characters'] = df_r1['characters'].apply(eval)\n",
    "df_r2['characters'] = df_r2['characters'].apply(eval)\n",
    "df_r1['confidences'] = df_r1['confidences'].apply(eval)\n",
    "df_r2['confidences'] = df_r2['confidences'].apply(eval)\n",
    "\n",
    "# Concatenate both\n",
    "df_combined = pd.concat([df_r1, df_r2], ignore_index=True)\n",
    "\n",
    "# Drop any duplicates (just in case same sentence appeared in both rounds)\n",
    "df_combined = df_combined.drop_duplicates(subset=['story_id', 'sentence_id'])\n",
    "\n",
    "# Save merged result\n",
    "df_combined.to_csv(\"pseudo_characters_combined_round1_2.csv\", index=False)\n",
    "\n",
    "# Count total\n",
    "print(f\"âœ… Total pseudo-labeled sentences after round 2: {len(df_combined)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f4194",
   "metadata": {},
   "source": [
    "## pseudo labelling round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22afd216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load sentence-tokenized full dataset\n",
    "df_tokens = pd.read_csv(\"../preprocessing/cerita_rakyat_tokenized_clean.csv\")\n",
    "\n",
    "# Load pseudo-labeled sentence-level characters\n",
    "df_chars = pd.read_csv(\"pseudo_characters_combined_round1_2.csv\")\n",
    "df_chars['characters'] = df_chars['characters'].apply(eval)\n",
    "\n",
    "# Filter token rows that match labeled sentences\n",
    "matched_ids = set(zip(df_chars['story_id'], df_chars['sentence_id']))\n",
    "df_matched = df_tokens[df_tokens.apply(lambda row: (row['story_id'], row['sentence_id']) in matched_ids, axis=1)].copy()\n",
    "\n",
    "# Merge character names to each token row\n",
    "df_merge = df_matched.merge(df_chars[['story_id', 'sentence_id', 'characters']], on=['story_id', 'sentence_id'], how='left')\n",
    "\n",
    "# Clean up possible float words\n",
    "df_merge['word'] = df_merge['word'].fillna('').astype(str)\n",
    "\n",
    "# Labeling function: B-PER / I-PER / O\n",
    "def label_token(word, char_list):\n",
    "    word = word.lower()\n",
    "    for char in char_list:\n",
    "        tokens = char.lower().split()\n",
    "        if word == tokens[0]:\n",
    "            return 'B-PER' if len(tokens) == 1 else 'B-PER'\n",
    "        elif word in tokens:\n",
    "            return 'I-PER'\n",
    "    return 'O'\n",
    "\n",
    "df_merge['TYPE2'] = df_merge.apply(lambda row: label_token(row['word'], row['characters']), axis=1)\n",
    "\n",
    "# Save word-level pseudo-labeled data\n",
    "df_pseudo = df_merge[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df_pseudo.to_csv(\"pseudo_word_level_labeled_combined_round1_2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c529b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training dataset for ner_model_v3 is ready!\n"
     ]
    }
   ],
   "source": [
    "# Load original manually labeled data\n",
    "df_manual = pd.read_csv(\"even_semi_annotated.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Load new pseudo-labeled tokens\n",
    "df_pseudo = pd.read_csv(\"pseudo_word_level_labeled_combined_round1_2.csv\")\n",
    "\n",
    "# Combine for training model v3\n",
    "df_train = pd.concat([df_manual, df_pseudo], ignore_index=True)\n",
    "df_train.to_csv(\"training_data_for_model_v3.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Training dataset for ner_model_v3 is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d334356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/7674 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7674/7674 [00:00<00:00, 10637.09 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1919/1919 [00:00<00:00, 10685.27 examples/s]\n",
      "C:\\Users\\rayssa\\AppData\\Local\\Temp\\ipykernel_51536\\3866255030.py:113: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4800/4800 09:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.880402</td>\n",
       "      <td>0.884709</td>\n",
       "      <td>0.882550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.069445</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.914373</td>\n",
       "      <td>0.883962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.074701</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.919572</td>\n",
       "      <td>0.896141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.090075</td>\n",
       "      <td>0.882248</td>\n",
       "      <td>0.907339</td>\n",
       "      <td>0.894618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.924771</td>\n",
       "      <td>0.897063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.112612</td>\n",
       "      <td>0.882109</td>\n",
       "      <td>0.910703</td>\n",
       "      <td>0.896178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.880562</td>\n",
       "      <td>0.919878</td>\n",
       "      <td>0.899791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.134505</td>\n",
       "      <td>0.882146</td>\n",
       "      <td>0.920183</td>\n",
       "      <td>0.900763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.140003</td>\n",
       "      <td>0.886586</td>\n",
       "      <td>0.915596</td>\n",
       "      <td>0.900858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.146722</td>\n",
       "      <td>0.877361</td>\n",
       "      <td>0.923242</td>\n",
       "      <td>0.899717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training complete! Model saved to ./ner_model_v3 ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# === Step 1: Load & preprocess ===\n",
    "df = pd.read_csv(\"training_data_for_model_v3.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df['word'] = df['word'].fillna('').astype(str)\n",
    "\n",
    "# Label mapping\n",
    "labels = sorted(df['TYPE2'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Map TYPE2 to numeric\n",
    "df['ner_tags'] = df['TYPE2'].map(label2id)\n",
    "\n",
    "# Group into sentences\n",
    "grouped = df.groupby(['story_id', 'sentence_id'])\n",
    "sentences = []\n",
    "tags = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    sentences.append(group['word'].tolist())\n",
    "    tags.append(group['ner_tags'].tolist())\n",
    "\n",
    "# HuggingFace Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': sentences,\n",
    "    'ner_tags': tags\n",
    "})\n",
    "\n",
    "# 80/20 split\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# === Step 2: Tokenizer and Model ===\n",
    "checkpoint = \"cahya/bert-base-indonesian-1.5G\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# === Step 3: Tokenize and align labels ===\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# === Step 4: Metrics ===\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    true_labels = [[id2label[l] for l in sent if l != -100] for sent in labels]\n",
    "    true_preds = [[id2label[p] for p, l in zip(sent_pred, sent_label) if l != -100]\n",
    "                  for sent_pred, sent_label in zip(preds, labels)]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }\n",
    "\n",
    "# === Step 5: TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model_v3\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs_v3\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# === Step 6: Trainer ===\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === Step 7: Train ===\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(\"./ner_model_v3\")\n",
    "tokenizer.save_pretrained(\"./ner_model_v3\")\n",
    "\n",
    "print(\"âœ… Training complete! Model saved to ./ner_model_v3 ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "159076a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Round 3 pseudo-labeled sentences: 257\n",
      "ğŸ”„ Still left for round 4: 58\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# === Step 1: Load ner_model_v3 ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model_v3\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model_v3\")\n",
    "\n",
    "pipeline = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",  # merge subwords nicely\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 2: Load leftover sentences ===\n",
    "df_leftover = pd.read_csv(\"leftover_sentences_for_next_round2.csv\")\n",
    "df_leftover['tokens'] = df_leftover['tokens'].apply(eval)  # convert string to list\n",
    "\n",
    "# === Step 3: Pseudo-labeling leftover round 3 ===\n",
    "confidence_threshold = 0.95\n",
    "\n",
    "high_conf_pseudo_labels = []\n",
    "still_low_conf = []\n",
    "\n",
    "for _, row in df_leftover.iterrows():\n",
    "    story_id = row['story_id']\n",
    "    sentence_id = row['sentence_id']\n",
    "    tokens = row['tokens']\n",
    "    sentence = \" \".join(tokens)\n",
    "\n",
    "    preds = pipeline(sentence)\n",
    "\n",
    "    char_names = []\n",
    "    confidences = []\n",
    "    low_conf = False\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            score = pred[\"score\"]\n",
    "            word = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "\n",
    "            if score >= confidence_threshold:\n",
    "                if word and len(word) > 1 and not word.isspace():\n",
    "                    char_names.append(word)\n",
    "                    confidences.append(round(score, 4))\n",
    "            else:\n",
    "                low_conf = True\n",
    "\n",
    "    if char_names:\n",
    "        high_conf_pseudo_labels.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(set(char_names)),\n",
    "            \"confidences\": confidences\n",
    "        })\n",
    "\n",
    "    if low_conf:\n",
    "        still_low_conf.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "# === Step 4: Save results ===\n",
    "pd.DataFrame(high_conf_pseudo_labels).to_csv(\"pseudo_characters_round3.csv\", index=False)\n",
    "pd.DataFrame(still_low_conf).to_csv(\"leftover_sentences_for_next_round3.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Round 3 pseudo-labeled sentences: {len(high_conf_pseudo_labels)}\")\n",
    "print(f\"ğŸ”„ Still left for round 4: {len(still_low_conf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b19f0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total pseudo-labeled sentences after round 3: 9113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all rounds\n",
    "df_r1 = pd.read_csv(\"pseudo_characters_high_confidence.csv\")\n",
    "df_r2 = pd.read_csv(\"pseudo_characters_round2.csv\")\n",
    "df_r3 = pd.read_csv(\"pseudo_characters_round3.csv\")\n",
    "\n",
    "# Ensure lists are evaluated properly\n",
    "for df in [df_r1, df_r2, df_r3]:\n",
    "    df['characters'] = df['characters'].apply(eval)\n",
    "    df['confidences'] = df['confidences'].apply(eval)\n",
    "\n",
    "# Merge\n",
    "df_all = pd.concat([df_r1, df_r2, df_r3], ignore_index=True)\n",
    "\n",
    "# Drop duplicate sentences just in case\n",
    "df_all = df_all.drop_duplicates(subset=['story_id', 'sentence_id'])\n",
    "\n",
    "# Save combined result\n",
    "df_all.to_csv(\"pseudo_characters_combined_round1_2_3.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Total pseudo-labeled sentences after round 3: {len(df_all)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a973a5c",
   "metadata": {},
   "source": [
    "## pseudo labelling round 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b729a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Token-level pseudo labels saved for ner_model_v4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load tokenized dataset and pseudo characters\n",
    "df_tokens = pd.read_csv(\"../preprocessing/cerita_rakyat_tokenized_clean.csv\")\n",
    "df_chars = pd.read_csv(\"pseudo_characters_combined_round1_2_3.csv\")\n",
    "\n",
    "df_chars['characters'] = df_chars['characters'].apply(eval)\n",
    "\n",
    "# Match sentences\n",
    "matched_ids = set(zip(df_chars['story_id'], df_chars['sentence_id']))\n",
    "df_matched = df_tokens[df_tokens.apply(lambda row: (row['story_id'], row['sentence_id']) in matched_ids, axis=1)].copy()\n",
    "\n",
    "# Merge character info into matched tokens\n",
    "df_merge = df_matched.merge(df_chars[['story_id', 'sentence_id', 'characters']], on=['story_id', 'sentence_id'], how='left')\n",
    "\n",
    "df_merge['word'] = df_merge['word'].fillna('').astype(str)\n",
    "\n",
    "# Label each token with B-PER/I-PER/O\n",
    "def label_token(word, char_list):\n",
    "    word = word.lower()\n",
    "    for char in char_list:\n",
    "        tokens = char.lower().split()\n",
    "        if word == tokens[0]:\n",
    "            return 'B-PER' if len(tokens) == 1 else 'B-PER'\n",
    "        elif word in tokens:\n",
    "            return 'I-PER'\n",
    "    return 'O'\n",
    "\n",
    "df_merge['TYPE2'] = df_merge.apply(lambda row: label_token(row['word'], row['characters']), axis=1)\n",
    "\n",
    "# Save token-level pseudo labels\n",
    "df_pseudo_tokens = df_merge[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df_pseudo_tokens.to_csv(\"pseudo_word_level_labeled_round1_2_3.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Token-level pseudo labels saved for ner_model_v4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da396d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training data ready for ner_model_v4 ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# Load manual labels\n",
    "df_manual = pd.read_csv(\"even_semi_annotated.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Load pseudo labels\n",
    "df_pseudo = pd.read_csv(\"pseudo_word_level_labeled_round1_2_3.csv\")\n",
    "\n",
    "# Merge them\n",
    "df_final = pd.concat([df_manual, df_pseudo], ignore_index=True)\n",
    "df_final.to_csv(\"training_data_for_model_v4.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Training data ready for ner_model_v4 ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c7d64",
   "metadata": {},
   "source": [
    "## pseudo labelling round 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d712b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/7752 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7752/7752 [00:00<00:00, 10566.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1939/1939 [00:00<00:00, 10821.64 examples/s]\n",
      "C:\\Users\\rayssa\\AppData\\Local\\Temp\\ipykernel_51536\\1621527156.py:117: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4850' max='4850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4850/4850 12:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.073729</td>\n",
       "      <td>0.859521</td>\n",
       "      <td>0.903038</td>\n",
       "      <td>0.880742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.871487</td>\n",
       "      <td>0.913470</td>\n",
       "      <td>0.891985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.087268</td>\n",
       "      <td>0.871362</td>\n",
       "      <td>0.918687</td>\n",
       "      <td>0.894399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>0.877521</td>\n",
       "      <td>0.907947</td>\n",
       "      <td>0.892475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.107603</td>\n",
       "      <td>0.884719</td>\n",
       "      <td>0.904265</td>\n",
       "      <td>0.894385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.133624</td>\n",
       "      <td>0.866955</td>\n",
       "      <td>0.921755</td>\n",
       "      <td>0.893516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.135506</td>\n",
       "      <td>0.867690</td>\n",
       "      <td>0.919607</td>\n",
       "      <td>0.892894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.137684</td>\n",
       "      <td>0.875734</td>\n",
       "      <td>0.914698</td>\n",
       "      <td>0.894792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.147369</td>\n",
       "      <td>0.865263</td>\n",
       "      <td>0.920221</td>\n",
       "      <td>0.891896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.146127</td>\n",
       "      <td>0.870537</td>\n",
       "      <td>0.920221</td>\n",
       "      <td>0.894690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training complete! Model saved at ./ner_model_v4 ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# === Step 1: Load training dataset ===\n",
    "df = pd.read_csv(\"training_data_for_model_v4.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df['word'] = df['word'].fillna('').astype(str)\n",
    "\n",
    "# Build label mappings\n",
    "labels = sorted(df['TYPE2'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Map TYPE2 to numeric\n",
    "df['ner_tags'] = df['TYPE2'].map(label2id)\n",
    "\n",
    "# Group into sentences\n",
    "grouped = df.groupby(['story_id', 'sentence_id'])\n",
    "sentences = []\n",
    "tags = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    sentences.append(group['word'].tolist())\n",
    "    tags.append(group['ner_tags'].tolist())\n",
    "\n",
    "# HuggingFace Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': sentences,\n",
    "    'ner_tags': tags\n",
    "})\n",
    "\n",
    "# Train/test split (80/20)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# === Step 2: Tokenizer and Model ===\n",
    "checkpoint = \"cahya/bert-base-indonesian-1.5G\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# === Step 3: Tokenize and align labels ===\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# === Step 4: Metric Computation ===\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    true_labels = [[id2label[label] for label in sent if label != -100] for sent in labels]\n",
    "    true_preds = [[id2label[pred] for (pred, label) in zip(sent_pred, sent_label) if label != -100]\n",
    "                  for sent_pred, sent_label in zip(preds, labels)]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }\n",
    "\n",
    "# === Step 5: TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model_v4\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs_v4\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# ğŸ’¬ Add Early Stopping\n",
    "from transformers import EarlyStoppingCallback\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
    "\n",
    "# === Step 6: Trainer ===\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === Step 7: Start Training ===\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(\"./ner_model_v4\")\n",
    "tokenizer.save_pretrained(\"./ner_model_v4\")\n",
    "\n",
    "print(\"âœ… Training complete! Model saved at ./ner_model_v4 ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98c7064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Round 4 pseudo-labeled sentences: 36\n",
      "ğŸ”„ Still left for round 5: 21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# === Step 1: Load ner_model_v4 ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model_v4\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model_v4\")\n",
    "\n",
    "pipeline = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 2: Load leftover sentences ===\n",
    "df_leftover = pd.read_csv(\"leftover_sentences_for_next_round3.csv\")\n",
    "df_leftover['tokens'] = df_leftover['tokens'].apply(eval)  # Convert from string to list\n",
    "\n",
    "# === Step 3: Pseudo-labeling leftover round 4 ===\n",
    "confidence_threshold = 0.95\n",
    "\n",
    "high_conf_pseudo_labels = []\n",
    "still_low_conf = []\n",
    "\n",
    "for _, row in df_leftover.iterrows():\n",
    "    story_id = row['story_id']\n",
    "    sentence_id = row['sentence_id']\n",
    "    tokens = row['tokens']\n",
    "    sentence = \" \".join(tokens)\n",
    "\n",
    "    preds = pipeline(sentence)\n",
    "\n",
    "    char_names = []\n",
    "    confidences = []\n",
    "    low_conf = False\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            score = pred[\"score\"]\n",
    "            word = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "\n",
    "            if score >= confidence_threshold:\n",
    "                if word and len(word) > 1 and not word.isspace():\n",
    "                    char_names.append(word)\n",
    "                    confidences.append(round(score, 4))\n",
    "            else:\n",
    "                low_conf = True\n",
    "\n",
    "    if char_names:\n",
    "        high_conf_pseudo_labels.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(set(char_names)),\n",
    "            \"confidences\": confidences\n",
    "        })\n",
    "\n",
    "    if low_conf:\n",
    "        still_low_conf.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "# === Step 4: Save results ===\n",
    "pd.DataFrame(high_conf_pseudo_labels).to_csv(\"pseudo_characters_round4.csv\", index=False)\n",
    "pd.DataFrame(still_low_conf).to_csv(\"leftover_sentences_for_next_round4.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Round 4 pseudo-labeled sentences: {len(high_conf_pseudo_labels)}\")\n",
    "print(f\"ğŸ”„ Still left for round 5: {len(still_low_conf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77e4b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total final pseudo-labeled sentences after round 4: 9128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all pseudo-labeled rounds\n",
    "df_r1 = pd.read_csv(\"pseudo_characters_high_confidence.csv\")\n",
    "df_r2 = pd.read_csv(\"pseudo_characters_round2.csv\")\n",
    "df_r3 = pd.read_csv(\"pseudo_characters_round3.csv\")\n",
    "df_r4 = pd.read_csv(\"pseudo_characters_round4.csv\")\n",
    "\n",
    "# Ensure 'characters' and 'confidences' columns are real lists\n",
    "for df in [df_r1, df_r2, df_r3, df_r4]:\n",
    "    df['characters'] = df['characters'].apply(eval)\n",
    "    df['confidences'] = df['confidences'].apply(eval)\n",
    "\n",
    "# Merge everything\n",
    "df_combined = pd.concat([df_r1, df_r2, df_r3, df_r4], ignore_index=True)\n",
    "\n",
    "# Drop duplicates (in case same sentence was predicted in multiple rounds)\n",
    "df_combined = df_combined.drop_duplicates(subset=['story_id', 'sentence_id'])\n",
    "\n",
    "# Save merged output\n",
    "df_combined.to_csv(\"pseudo_characters_combined_round1_2_3_4.csv\", index=False)\n",
    "\n",
    "# Show summary\n",
    "print(f\"âœ… Total final pseudo-labeled sentences after round 4: {len(df_combined)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d8932",
   "metadata": {},
   "source": [
    "## model 4 rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cc13844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Round 4 (fixed) pseudo-labeled sentences: 36\n",
      "ğŸ”„ Still leftover for round 5: 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# === Step 1: Load ner_model_v4 ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model_v4\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model_v4\")\n",
    "\n",
    "pipeline = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 2: Load leftovers ===\n",
    "df_leftover = pd.read_csv(\"leftover_sentences_for_next_round3.csv\")\n",
    "df_leftover['tokens'] = df_leftover['tokens'].apply(eval)  # Convert from string to list\n",
    "\n",
    "# === Step 3: Pseudo-label properly ===\n",
    "confidence_threshold = 0.95\n",
    "\n",
    "high_conf_pseudo_labels = []\n",
    "still_low_conf = []\n",
    "\n",
    "for _, row in df_leftover.iterrows():\n",
    "    story_id = row['story_id']\n",
    "    sentence_id = row['sentence_id']\n",
    "    tokens = row['tokens']\n",
    "    sentence = \" \".join(tokens)\n",
    "\n",
    "    preds = pipeline(sentence)\n",
    "\n",
    "    char_names = []\n",
    "    confidences = []\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            score = pred[\"score\"]\n",
    "            word = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "\n",
    "            if score >= confidence_threshold:\n",
    "                if word and len(word) > 1 and not word.isspace():\n",
    "                    char_names.append(word)\n",
    "                    confidences.append(round(score, 4))\n",
    "\n",
    "    # === New fixed logic:\n",
    "    if char_names:\n",
    "        high_conf_pseudo_labels.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(set(char_names)),\n",
    "            \"confidences\": confidences\n",
    "        })\n",
    "    else:\n",
    "        # Always keep unconfident or empty sentences for next round\n",
    "        still_low_conf.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "# === Step 4: Save outputs ===\n",
    "pd.DataFrame(high_conf_pseudo_labels).to_csv(\"pseudo_characters_round4_fixed.csv\", index=False)\n",
    "pd.DataFrame(still_low_conf).to_csv(\"leftover_sentences_for_next_round4_fixed.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Round 4 (fixed) pseudo-labeled sentences: {len(high_conf_pseudo_labels)}\")\n",
    "print(f\"ğŸ”„ Still leftover for round 5: {len(still_low_conf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2524bf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final pseudo-labeled sentences (after fix): 9128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all pseudo-labeled rounds\n",
    "df_r1 = pd.read_csv(\"pseudo_characters_high_confidence.csv\")\n",
    "df_r2 = pd.read_csv(\"pseudo_characters_round2.csv\")\n",
    "df_r3 = pd.read_csv(\"pseudo_characters_round3.csv\")\n",
    "df_r4_fixed = pd.read_csv(\"pseudo_characters_round4_fixed.csv\")  # <<< use the FIXED one!\n",
    "\n",
    "# Ensure 'characters' and 'confidences' are real lists\n",
    "for df in [df_r1, df_r2, df_r3, df_r4_fixed]:\n",
    "    df['characters'] = df['characters'].apply(eval)\n",
    "    df['confidences'] = df['confidences'].apply(eval)\n",
    "\n",
    "# Merge everything\n",
    "df_all = pd.concat([df_r1, df_r2, df_r3, df_r4_fixed], ignore_index=True)\n",
    "\n",
    "# Drop duplicates (same story_id + sentence_id)\n",
    "df_all = df_all.drop_duplicates(subset=['story_id', 'sentence_id'])\n",
    "\n",
    "# Save final combined file\n",
    "df_all.to_csv(\"pseudo_characters_combined_round1_2_3_4_fixed.csv\", index=False)\n",
    "\n",
    "# Show total\n",
    "print(f\"âœ… Final pseudo-labeled sentences (after fix): {len(df_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b75d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total unique sentences: 9128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed.csv\")\n",
    "\n",
    "# Count unique (story_id, sentence_id) pairs\n",
    "unique_sentences = df[['story_id', 'sentence_id']].drop_duplicates()\n",
    "total_sentences = unique_sentences.shape[0]\n",
    "\n",
    "print(f\"âœ… Total unique sentences: {total_sentences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707a6022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total unique sentences: 9128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4.csv\")\n",
    "\n",
    "# Count unique (story_id, sentence_id) pairs\n",
    "unique_sentences = df[['story_id', 'sentence_id']].drop_duplicates()\n",
    "total_sentences = unique_sentences.shape[0]\n",
    "\n",
    "print(f\"âœ… Total unique sentences: {total_sentences}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbb2a4",
   "metadata": {},
   "source": [
    "## pseudo labelling round 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b60ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Token-level pseudo-labeled data saved as pseudo_word_level_labeled_round1_2_3_4_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load tokenized clean text and combined pseudo labels ===\n",
    "df_tokens = pd.read_csv(\"../preprocessing/cerita_rakyat_tokenized_clean.csv\")\n",
    "df_chars = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed.csv\")\n",
    "\n",
    "# Ensure characters are lists\n",
    "df_chars['characters'] = df_chars['characters'].apply(eval)\n",
    "\n",
    "# === Step 2: Match sentences ===\n",
    "matched_ids = set(zip(df_chars['story_id'], df_chars['sentence_id']))\n",
    "df_matched = df_tokens[df_tokens.apply(lambda row: (row['story_id'], row['sentence_id']) in matched_ids, axis=1)].copy()\n",
    "\n",
    "# Merge character info into tokens\n",
    "df_merge = df_matched.merge(df_chars[['story_id', 'sentence_id', 'characters']], on=['story_id', 'sentence_id'], how='left')\n",
    "\n",
    "# Clean up NaNs\n",
    "df_merge['word'] = df_merge['word'].fillna('').astype(str)\n",
    "\n",
    "# === Step 3: Assign B-PER, I-PER, or O ===\n",
    "def label_token(word, char_list):\n",
    "    word = word.lower()\n",
    "    for char in char_list:\n",
    "        tokens = char.lower().split()\n",
    "        if word == tokens[0]:\n",
    "            return 'B-PER' if len(tokens) == 1 else 'B-PER'\n",
    "        elif word in tokens:\n",
    "            return 'I-PER'\n",
    "    return 'O'\n",
    "\n",
    "df_merge['TYPE2'] = df_merge.apply(lambda row: label_token(row['word'], row['characters']), axis=1)\n",
    "\n",
    "# === Step 4: Save the word-level pseudo labeled dataset ===\n",
    "df_pseudo_tokens = df_merge[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df_pseudo_tokens.to_csv(\"pseudo_word_level_labeled_round1_2_3_4_fixed.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Token-level pseudo-labeled data saved as pseudo_word_level_labeled_round1_2_3_4_fixed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5823a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final training dataset for ner_model_v5 is ready! Total rows: 154532\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load manual annotated data\n",
    "df_manual = pd.read_csv(\"even_semi_annotated.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Load full pseudo-labeled token data\n",
    "df_pseudo = pd.read_csv(\"pseudo_word_level_labeled_round1_2_3_4_fixed.csv\")\n",
    "\n",
    "# Merge together\n",
    "df_final = pd.concat([df_manual, df_pseudo], ignore_index=True)\n",
    "\n",
    "# Save final merged training dataset\n",
    "df_final.to_csv(\"training_data_for_model_v5.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Final training dataset for ner_model_v5 is ready! Total rows: {len(df_final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c97031e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/7764 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7764/7764 [00:00<00:00, 10520.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1942/1942 [00:00<00:00, 10698.77 examples/s]\n",
      "C:\\Users\\rayssa\\AppData\\Local\\Temp\\ipykernel_51536\\2098745763.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4860' max='4860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4860/4860 09:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.894005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.074815</td>\n",
       "      <td>0.876579</td>\n",
       "      <td>0.889386</td>\n",
       "      <td>0.882936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.073273</td>\n",
       "      <td>0.890737</td>\n",
       "      <td>0.926058</td>\n",
       "      <td>0.908054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.892744</td>\n",
       "      <td>0.920692</td>\n",
       "      <td>0.906502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.093736</td>\n",
       "      <td>0.902696</td>\n",
       "      <td>0.918306</td>\n",
       "      <td>0.910435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.093422</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.912343</td>\n",
       "      <td>0.910579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.107302</td>\n",
       "      <td>0.907149</td>\n",
       "      <td>0.911747</td>\n",
       "      <td>0.909442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.106827</td>\n",
       "      <td>0.900748</td>\n",
       "      <td>0.933512</td>\n",
       "      <td>0.916837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.116154</td>\n",
       "      <td>0.897711</td>\n",
       "      <td>0.923673</td>\n",
       "      <td>0.910507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.117777</td>\n",
       "      <td>0.895887</td>\n",
       "      <td>0.928742</td>\n",
       "      <td>0.912019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: b-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: b-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: b-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\rayssa\\Documents\\thesis\\venv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: b-PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training complete! Model saved at ./ner_model_v5 ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# === Step 1: Load the dataset ===\n",
    "df = pd.read_csv(\"training_data_for_model_v5.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df['word'] = df['word'].fillna('').astype(str)\n",
    "\n",
    "# Build label mappings\n",
    "labels = sorted(df['TYPE2'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Map TYPE2 to numeric\n",
    "df['ner_tags'] = df['TYPE2'].map(label2id)\n",
    "\n",
    "# Group into sentences\n",
    "grouped = df.groupby(['story_id', 'sentence_id'])\n",
    "sentences = []\n",
    "tags = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    sentences.append(group['word'].tolist())\n",
    "    tags.append(group['ner_tags'].tolist())\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': sentences,\n",
    "    'ner_tags': tags\n",
    "})\n",
    "\n",
    "# 80/20 split\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# === Step 2: Load model and tokenizer ===\n",
    "checkpoint = \"cahya/bert-base-indonesian-1.5G\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# === Step 3: Tokenize and align labels ===\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# === Step 4: Metrics ===\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    true_labels = [[id2label[label] for label in sent if label != -100] for sent in labels]\n",
    "    true_preds = [[id2label[pred] for (pred, label) in zip(sent_pred, sent_label) if label != -100]\n",
    "                  for sent_pred, sent_label in zip(preds, labels)]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }\n",
    "\n",
    "# === Step 5: TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model_v5\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs_v5\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# === Step 6: Trainer ===\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Early stopping (optional but recommended!)\n",
    "from transformers import EarlyStoppingCallback\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
    "\n",
    "# === Step 7: Start Training ===\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(\"./ner_model_v5\")\n",
    "tokenizer.save_pretrained(\"./ner_model_v5\")\n",
    "\n",
    "print(\"âœ… Training complete! Model saved at ./ner_model_v5 ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2819c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Round 5 pseudo-labeled sentences: 6\n",
      "ğŸ”„ Still leftover for round 6: 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# === Step 1: Load ner_model_v5 ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model_v5\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model_v5\")\n",
    "\n",
    "pipeline = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 2: Load leftover sentences ===\n",
    "df_leftover = pd.read_csv(\"leftover_sentences_for_next_round4_fixed.csv\")\n",
    "df_leftover['tokens'] = df_leftover['tokens'].apply(eval)  # Convert from string to list\n",
    "\n",
    "# === Step 3: Pseudo-labeling round 5 ===\n",
    "confidence_threshold = 0.95\n",
    "\n",
    "high_conf_pseudo_labels = []\n",
    "still_low_conf = []\n",
    "\n",
    "for _, row in df_leftover.iterrows():\n",
    "    story_id = row['story_id']\n",
    "    sentence_id = row['sentence_id']\n",
    "    tokens = row['tokens']\n",
    "    sentence = \" \".join(tokens)\n",
    "\n",
    "    preds = pipeline(sentence)\n",
    "\n",
    "    char_names = []\n",
    "    confidences = []\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            score = pred[\"score\"]\n",
    "            word = pred[\"word\"].replace(\"##\", \"\").strip().title()\n",
    "\n",
    "            if score >= confidence_threshold:\n",
    "                if word and len(word) > 1 and not word.isspace():\n",
    "                    char_names.append(word)\n",
    "                    confidences.append(round(score, 4))\n",
    "\n",
    "    if char_names:\n",
    "        high_conf_pseudo_labels.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": list(set(char_names)),\n",
    "            \"confidences\": confidences\n",
    "        })\n",
    "    else:\n",
    "        # Always keep leftovers even if nothing detected\n",
    "        still_low_conf.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"tokens\": tokens\n",
    "        })\n",
    "\n",
    "# === Step 4: Save results ===\n",
    "pd.DataFrame(high_conf_pseudo_labels).to_csv(\"pseudo_characters_round5.csv\", index=False)\n",
    "pd.DataFrame(still_low_conf).to_csv(\"leftover_sentences_for_next_round5.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Round 5 pseudo-labeled sentences: {len(high_conf_pseudo_labels)}\")\n",
    "print(f\"ğŸ”„ Still leftover for round 6: {len(still_low_conf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da150647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed phrase ('Beru', 'Tandang', 'Karo') in sentence 14\n",
      "âœ… Fixed phrase ('Beru', 'Tandang', 'Karo') in sentence 31\n",
      "âœ… Fixed phrase ('Beru', 'Tandang', 'Meriah') in sentence 31\n",
      "âœ… Fixed phrase ('Beru', 'Tandang', 'Karo') in sentence 58\n",
      "âœ… Fixed phrase ('Beru', 'Tandang', 'Karo') in sentence 89\n",
      "âœ… Full correction saved to pseudo_word_level_labeled_round1_2_3_4_fixed_corrected.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your pseudo-word-level file\n",
    "df = pd.read_csv(\"pseudo_word_level_labeled_round1_2_3_4_fixed.csv\")\n",
    "\n",
    "# === Step 1: Define targets globally ===\n",
    "phrases_to_fix = {\n",
    "    (\"Beru\", \"Tandang\", \"Karo\"): [\"B-PER\", \"I-PER\", \"I-PER\"],\n",
    "    (\"Beru\", \"Tandang\", \"Meriah\"): [\"B-PER\", \"I-PER\", \"I-PER\"]\n",
    "}\n",
    "\n",
    "# === Step 2: Go through all story_id = 13 ===\n",
    "for sentence_id in df[df['story_id'] == 13]['sentence_id'].unique():\n",
    "    mask = (df['story_id'] == 13) & (df['sentence_id'] == sentence_id)\n",
    "    words = df[mask]['word'].tolist()\n",
    "\n",
    "    for phrase, labels in phrases_to_fix.items():\n",
    "        phrase_length = len(phrase)\n",
    "\n",
    "        for idx in range(len(words) - phrase_length + 1):\n",
    "            if tuple(words[idx:idx+phrase_length]) == phrase:\n",
    "                for j in range(phrase_length):\n",
    "                    df_idx = df[mask].index[idx+j]\n",
    "                    df.at[df_idx, 'TYPE2'] = labels[j]\n",
    "                print(f\"âœ… Fixed phrase {phrase} in sentence {sentence_id}\")\n",
    "\n",
    "# === Step 3: Save new corrected file ===\n",
    "df.to_csv(\"pseudo_word_level_labeled_round1_2_3_4_fixed_corrected.csv\", index=False)\n",
    "print(\"âœ… Full correction saved to pseudo_word_level_labeled_round1_2_3_4_fixed_corrected.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc914a03",
   "metadata": {},
   "source": [
    "## pseudo labelling v5 part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d13c050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final training dataset created: 154532 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load manual annotated data\n",
    "df_manual = pd.read_csv(\"even_semi_annotated.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Load corrected pseudo-labeled data\n",
    "df_pseudo = pd.read_csv(\"pseudo_word_level_labeled_round1_2_3_4_fixed_corrected.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "\n",
    "# Merge them together\n",
    "df_final = pd.concat([df_manual, df_pseudo], ignore_index=True)\n",
    "\n",
    "# Save final training file\n",
    "df_final.to_csv(\"training_data_for_model_v5.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Final training dataset created: {len(df_final)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b744e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/7764 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7764/7764 [00:00<00:00, 10120.09 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1942/1942 [00:00<00:00, 10484.77 examples/s]\n",
      "C:\\Users\\rayssa\\AppData\\Local\\Temp\\ipykernel_51536\\3879113616.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2916' max='4860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2916/4860 05:27 < 03:38, 8.89 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>0.892463</td>\n",
       "      <td>0.867998</td>\n",
       "      <td>0.880060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.888688</td>\n",
       "      <td>0.877831</td>\n",
       "      <td>0.883226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.073406</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.909416</td>\n",
       "      <td>0.902825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>0.897003</td>\n",
       "      <td>0.918653</td>\n",
       "      <td>0.907699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.889813</td>\n",
       "      <td>0.924017</td>\n",
       "      <td>0.906593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.098325</td>\n",
       "      <td>0.888186</td>\n",
       "      <td>0.920739</td>\n",
       "      <td>0.904170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training complete! Model saved at ./ner_model_v5 ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# === Step 1: Load your final dataset ===\n",
    "df = pd.read_csv(\"training_data_for_model_v5.csv\")[['story_id', 'sentence_id', 'word', 'TYPE2']]\n",
    "df['word'] = df['word'].fillna('').astype(str)\n",
    "\n",
    "# Build label mappings\n",
    "labels = sorted(df['TYPE2'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Map TYPE2 to numeric\n",
    "df['ner_tags'] = df['TYPE2'].map(label2id)\n",
    "\n",
    "# Group into sentences\n",
    "grouped = df.groupby(['story_id', 'sentence_id'])\n",
    "sentences = []\n",
    "tags = []\n",
    "\n",
    "for _, group in grouped:\n",
    "    sentences.append(group['word'].tolist())\n",
    "    tags.append(group['ner_tags'].tolist())\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': sentences,\n",
    "    'ner_tags': tags\n",
    "})\n",
    "\n",
    "# Train/test split (80/20)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# === Step 2: Load model and tokenizer ===\n",
    "checkpoint = \"cahya/bert-base-indonesian-1.5G\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# === Step 3: Tokenize and align labels ===\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# === Step 4: Metrics ===\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    true_labels = [[id2label[label] for label in sent if label != -100] for sent in labels]\n",
    "    true_preds = [[id2label[pred] for (pred, label) in zip(sent_pred, sent_label) if label != -100]\n",
    "                  for sent_pred, sent_label in zip(preds, labels)]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds)\n",
    "    }\n",
    "\n",
    "# === Step 5: TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ner_model_v5\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs_v5\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# === Step 6: Trainer setup ===\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Early stopping (recommended)\n",
    "from transformers import EarlyStoppingCallback\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
    "\n",
    "# === Step 7: Start training ===\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(\"./ner_model_v5\")\n",
    "tokenizer.save_pretrained(\"./ner_model_v5\")\n",
    "\n",
    "print(\"âœ… Training complete! Model saved at ./ner_model_v5 ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "684e9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Finished pseudo-labeling. Hereâ€™s a sample:\n",
      "    story_id  sentence_id                 word  confidence\n",
      "0         10           66            mataniari      0.9681\n",
      "1         13           72                  ber      0.9983\n",
      "2         13           72       u tandang karo      0.9925\n",
      "3         13           72                  ber      0.9982\n",
      "4         13           72     u tandang meriah      0.9944\n",
      "5         18           90              ketujuh      0.7520\n",
      "6         31            0  sri baduga maharaja      0.7927\n",
      "7         31            0      prabu siliwangi      0.8769\n",
      "8         32           75             ayam adu      0.8743\n",
      "9         32           75      raja riak bakau      0.8818\n",
      "10        32           75                kakek      0.7870\n",
      "11        32           75                 ayam      0.7738\n",
      "12        32           75      raja riak bakau      0.6435\n",
      "13        76           13                kakek      0.9610\n",
      "14        76           13                nenek      0.8871\n",
      "15        94           82                   ha      0.7412\n",
      "16        94           82                   na      0.7122\n",
      "17        94           82                   ca      0.5172\n",
      "18        94           82                   ra      0.4578\n",
      "19        94           82                   da      0.8295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import TokenClassificationPipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# === Step 1: Load ner_model_v5 ===\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./ner_model_v5\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./ner_model_v5\")\n",
    "\n",
    "pipeline = TokenClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# === Step 2: Load leftovers ===\n",
    "df_leftover = pd.read_csv(\"leftover_sentences_for_next_round4_fixed.csv\")\n",
    "df_leftover['tokens'] = df_leftover['tokens'].apply(eval)  # convert from string to list\n",
    "\n",
    "# === Step 3: Pseudo-label all, with confidence logging ===\n",
    "all_predictions = []\n",
    "\n",
    "for _, row in df_leftover.iterrows():\n",
    "    story_id = row['story_id']\n",
    "    sentence_id = row['sentence_id']\n",
    "    tokens = row['tokens']\n",
    "    sentence = \" \".join(tokens)\n",
    "\n",
    "    preds = pipeline(sentence)\n",
    "\n",
    "    for pred in preds:\n",
    "        if pred[\"entity_group\"] == \"PER\":\n",
    "            all_predictions.append({\n",
    "                \"story_id\": story_id,\n",
    "                \"sentence_id\": sentence_id,\n",
    "                \"word\": pred[\"word\"].replace(\"##\", \"\").strip(),\n",
    "                \"confidence\": round(pred[\"score\"], 4)\n",
    "            })\n",
    "\n",
    "# === Step 4: Save and show ===\n",
    "df_preds = pd.DataFrame(all_predictions)\n",
    "df_preds.to_csv(\"pseudo_predictions_from_leftovers_v5.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Finished pseudo-labeling. Hereâ€™s a sample:\")\n",
    "print(df_preds.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c882af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merging complete! Corrected file saved as pseudo_predictions_from_leftovers_v5_fixed.csv\n",
      "    story_id  sentence_id                 word  confidence\n",
      "0         10           66            mataniari      0.9681\n",
      "1         13           72    Beru Tandang Karo      0.9954\n",
      "2         13           72  Beru Tandang Meriah      0.9963\n",
      "3         18           90              ketujuh      0.7520\n",
      "4         31            0  sri baduga maharaja      0.7927\n",
      "5         31            0      prabu siliwangi      0.8769\n",
      "6         32           75             ayam adu      0.8743\n",
      "7         32           75      raja riak bakau      0.8818\n",
      "8         32           75                kakek      0.7870\n",
      "9         32           75                 ayam      0.7738\n",
      "10        32           75      raja riak bakau      0.6435\n",
      "11        76           13                kakek      0.9610\n",
      "12        76           13                nenek      0.8871\n",
      "13        94           82                   ha      0.7412\n",
      "14        94           82                   na      0.7122\n",
      "15        94           82                   ca      0.5172\n",
      "16        94           82                   ra      0.4578\n",
      "17        94           82                   da      0.8295\n",
      "18        94           82                   pa      0.6661\n",
      "19        94           82                   da      0.6159\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your raw prediction result\n",
    "df = pd.read_csv(\"pseudo_predictions_from_leftovers_v5.csv\")\n",
    "\n",
    "# === Step 1: Define merging rules ===\n",
    "# For combining \"ber\" + \"u tandang karo\" and \"ber\" + \"u tandang meriah\"\n",
    "merge_targets = {\n",
    "    (\"ber\", \"u tandang karo\"): \"Beru Tandang Karo\",\n",
    "    (\"ber\", \"u tandang meriah\"): \"Beru Tandang Meriah\"\n",
    "}\n",
    "\n",
    "fixed_rows = []\n",
    "skip_next = False\n",
    "\n",
    "# === Step 2: Scan and merge ===\n",
    "for i in range(len(df) - 1):\n",
    "    if skip_next:\n",
    "        skip_next = False\n",
    "        continue\n",
    "\n",
    "    row1 = df.iloc[i]\n",
    "    row2 = df.iloc[i+1]\n",
    "\n",
    "    key = (row1['word'].lower(), row2['word'].lower())\n",
    "\n",
    "    if key in merge_targets:\n",
    "        merged_name = merge_targets[key]\n",
    "        avg_conf = round((row1['confidence'] + row2['confidence']) / 2, 4)\n",
    "\n",
    "        fixed_rows.append({\n",
    "            \"story_id\": row1['story_id'],\n",
    "            \"sentence_id\": row1['sentence_id'],\n",
    "            \"word\": merged_name,\n",
    "            \"confidence\": avg_conf\n",
    "        })\n",
    "\n",
    "        skip_next = True  # Skip next row because it's already merged\n",
    "    else:\n",
    "        fixed_rows.append({\n",
    "            \"story_id\": row1['story_id'],\n",
    "            \"sentence_id\": row1['sentence_id'],\n",
    "            \"word\": row1['word'],\n",
    "            \"confidence\": row1['confidence']\n",
    "        })\n",
    "\n",
    "# Handle last row if not merged\n",
    "if not skip_next and len(df) > 0:\n",
    "    last_row = df.iloc[-1]\n",
    "    fixed_rows.append({\n",
    "        \"story_id\": last_row['story_id'],\n",
    "        \"sentence_id\": last_row['sentence_id'],\n",
    "        \"word\": last_row['word'],\n",
    "        \"confidence\": last_row['confidence']\n",
    "    })\n",
    "\n",
    "# === Step 3: Save clean fixed version ===\n",
    "df_fixed = pd.DataFrame(fixed_rows)\n",
    "df_fixed.to_csv(\"pseudo_predictions_from_leftovers_v5_fixed.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Merging complete! Corrected file saved as pseudo_predictions_from_leftovers_v5_fixed.csv\")\n",
    "print(df_fixed.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9e78edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rebuilt pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv from corrected token labels\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load corrected token-level pseudo labels\n",
    "df_tokens = pd.read_csv(\"pseudo_word_level_labeled_round1_2_3_4_fixed_corrected.csv\")\n",
    "\n",
    "# Group by sentence\n",
    "grouped = df_tokens.groupby(['story_id', 'sentence_id'])\n",
    "\n",
    "sentence_level = []\n",
    "\n",
    "for (story_id, sentence_id), group in grouped:\n",
    "    tokens = group['word'].tolist()\n",
    "    labels = group['TYPE2'].tolist()\n",
    "\n",
    "    character_names = []\n",
    "    current_char = []\n",
    "\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label == \"B-PER\":\n",
    "            if current_char:\n",
    "                character_names.append(\" \".join(current_char))\n",
    "                current_char = []\n",
    "            current_char = [token]\n",
    "        elif label == \"I-PER\":\n",
    "            current_char.append(token)\n",
    "        else:\n",
    "            if current_char:\n",
    "                character_names.append(\" \".join(current_char))\n",
    "                current_char = []\n",
    "\n",
    "    if current_char:\n",
    "        character_names.append(\" \".join(current_char))\n",
    "\n",
    "    # Save if any character found\n",
    "    if character_names:\n",
    "        sentence_level.append({\n",
    "            \"story_id\": story_id,\n",
    "            \"sentence_id\": sentence_id,\n",
    "            \"characters\": character_names,\n",
    "            \"confidences\": [-1.0 for _ in character_names]  # -1 because original token labels have no confidence\n",
    "        })\n",
    "\n",
    "# Save new clean sentence-level pseudo characters\n",
    "df_sentences = pd.DataFrame(sentence_level)\n",
    "df_sentences.to_csv(\"pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Rebuilt pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv from corrected token labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5a3d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Exported 9 high-confidence predictions to pseudo_predictions_high_confidence_round5_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the corrected pseudo prediction file\n",
    "df_fixed = pd.read_csv(\"pseudo_predictions_from_leftovers_v5_fixed.csv\")\n",
    "\n",
    "# Filter only high-confidence predictions (>95%)\n",
    "df_high_conf_fixed = df_fixed[df_fixed['confidence'] >= 0.95]\n",
    "\n",
    "# Save high-confidence results\n",
    "df_high_conf_fixed.to_csv(\"pseudo_predictions_high_confidence_round5_fixed.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Exported {len(df_high_conf_fixed)} high-confidence predictions to pseudo_predictions_high_confidence_round5_fixed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "660db1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final pseudo_characters_combined_round1_2_3_4_5_final.csv is clean and ready!\n"
     ]
    }
   ],
   "source": [
    "# Load corrected rebuilt pseudo characters\n",
    "df_old = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv\")\n",
    "\n",
    "# Load new round 5 high confidence predictions\n",
    "df_new = pd.read_csv(\"pseudo_predictions_high_confidence_round5_fixed.csv\")\n",
    "\n",
    "# Prepare new format to match\n",
    "df_new['characters'] = df_new['word'].apply(lambda x: [x])\n",
    "df_new['confidences'] = df_new['confidence'].apply(lambda x: [round(x, 4)])\n",
    "\n",
    "df_new = df_new[['story_id', 'sentence_id', 'characters', 'confidences']]\n",
    "\n",
    "# Merge old and new\n",
    "df_all = pd.concat([df_old, df_new], ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df_all = df_all.drop_duplicates(subset=['story_id', 'sentence_id'])\n",
    "\n",
    "# Save final merged pseudo characters\n",
    "df_all.to_csv(\"pseudo_characters_combined_round1_2_3_4_5_final.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Final pseudo_characters_combined_round1_2_3_4_5_final.csv is clean and ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ce3e08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total unique sentences: 8817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_5_final.csv\")\n",
    "\n",
    "# Count unique (story_id, sentence_id) pairs\n",
    "unique_sentences = df[['story_id', 'sentence_id']].drop_duplicates()\n",
    "total_sentences = unique_sentences.shape[0]\n",
    "\n",
    "print(f\"âœ… Total unique sentences: {total_sentences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c410aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54d3a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total unique sentences: 8817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_5_final.csv\")\n",
    "\n",
    "# Count unique (story_id, sentence_id) pairs\n",
    "total_sentences = df.groupby(['story_id', 'sentence_id']).ngroups\n",
    "\n",
    "print(f\"âœ… Total unique sentences: {total_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce773756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¾ Total entries (rows): 9128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4.csv\")\n",
    "total_entries = len(df)\n",
    "print(f\"ğŸ§¾ Total entries (rows): {total_entries}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3670ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¾ Total entries (rows): 9128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed.csv\")\n",
    "total_entries = len(df)\n",
    "print(f\"ğŸ§¾ Total entries (rows): {total_entries}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7853c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¾ Total entries (rows): 8813\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv\")\n",
    "total_entries = len(df)\n",
    "print(f\"ğŸ§¾ Total entries (rows): {total_entries}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f9644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows: 315\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed.csv\")\n",
    "df_rebuild = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv\")\n",
    "\n",
    "# Find missing (story_id, sentence_id) from rebuild\n",
    "merged = df_all.merge(df_rebuild, on=[\"story_id\", \"sentence_id\"], how=\"left\", indicator=True)\n",
    "missing = merged[merged['_merge'] == 'left_only']\n",
    "print(f\"Missing rows: {len(missing)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba7c4027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Total missing rows in rebuild: 315\n",
      "      story_id  sentence_id             characters_x confidences_x\n",
      "179          6           32               ['Ibunya']      [0.9975]\n",
      "300          9           48  ['Bidadari - Bidadari']      [0.9839]\n",
      "409         10          208    ['Menteri - Menteri']        [0.98]\n",
      "662         15           77              ['Hatoban']      [0.9706]\n",
      "1331        22           43      ['Burung - Burung']       [0.975]\n",
      "1333        22           51               ['Sitiii']      [0.9906]\n",
      "1336        22           59               ['Sitiii']      [0.9913]\n",
      "1686        26           97          ['Ikan - Ikan']      [0.9936]\n",
      "1687        26           98          ['Ikan - Ikan']      [0.9891]\n",
      "3310        75           38        ['Lipan - Lipan']      [0.9512]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both versions\n",
    "df_original = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed.csv\")\n",
    "df_rebuild = pd.read_csv(\"pseudo_characters_combined_round1_2_3_4_fixed_rebuild.csv\")\n",
    "\n",
    "# Merge to find what's missing in rebuild\n",
    "merged = df_original.merge(\n",
    "    df_rebuild,\n",
    "    on=[\"story_id\", \"sentence_id\"],\n",
    "    how=\"left\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Filter to keep only rows that are missing in the rebuild\n",
    "missing = merged[merged['_merge'] == 'left_only']\n",
    "\n",
    "# Show the number and the actual rows\n",
    "print(f\"âŒ Total missing rows in rebuild: {len(missing)}\")\n",
    "print(missing[['story_id', 'sentence_id', 'characters_x', 'confidences_x']].head(10))  # show first 10\n",
    "\n",
    "# Optionally save to file\n",
    "missing[['story_id', 'sentence_id', 'characters_x', 'confidences_x']].to_csv(\"missing_from_rebuild.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa067cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Duplicate (story_id, sentence_id) pairs: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.duplicated(subset=['story_id', 'sentence_id']).sum()\n",
    "print(f\"ğŸ” Duplicate (story_id, sentence_id) pairs: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51666cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
