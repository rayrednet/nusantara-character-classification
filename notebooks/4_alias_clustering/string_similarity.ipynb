{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214ac55f",
   "metadata": {},
   "source": [
    "# alias clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac7372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Alias clustering complete with exclusion logic! Saved as alias_clusters_all.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import textdistance\n",
    "\n",
    "# Load the normalized data\n",
    "df = pd.read_csv(\"normalized_characters_all.csv\")\n",
    "df['normalized_characters'] = df['normalized_characters'].apply(eval)\n",
    "\n",
    "# Pointer list\n",
    "POINTERS = [\n",
    "    'ibu', 'pak', 'puteri', 'permaisuri', 'raja', 'putera', 'ayah', 'istri', 'suami', 'uwak', 'menteri',\n",
    "    'bunda', 'anak', 'kakak', 'adik', 'kakek', 'orang tua', 'tetangga', 'putri', 'beru tandang',\n",
    "    'putroe', 'telangkai', 'tuhan', 'abang'\n",
    "]\n",
    "\n",
    "# Anti-merge exclusion pairs (based on semantic contradiction)\n",
    "EXCLUDE_PAIRS = [\n",
    "    ('bungsu', 'sulung'),\n",
    "    ('muda', 'tua'),\n",
    "    ('mahkota', 'biasa')\n",
    "]\n",
    "\n",
    "# Compute similarity scores\n",
    "def compute_similarity(s1, s2):\n",
    "    return {\n",
    "        'jaccard': textdistance.jaccard(s1, s2),\n",
    "        'jaro': textdistance.jaro(s1, s2),\n",
    "    }\n",
    "\n",
    "# Normalize alias\n",
    "def normalize(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Check if an exclusion pair exists\n",
    "def is_excluded(name1, name2):\n",
    "    name1 = normalize(name1)\n",
    "    name2 = normalize(name2)\n",
    "    for a, b in EXCLUDE_PAIRS:\n",
    "        if a in name1 and b in name2 or b in name1 and a in name2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Cluster characters without pointers\n",
    "def cluster_without_pointers(characters_list, aliases_clusters, threshold):\n",
    "    cluster_id = len(aliases_clusters) + 1\n",
    "\n",
    "    # üß± Centralized false merge list\n",
    "    false_merge_blacklist = set([\n",
    "        ('raja', 'rajawali'),\n",
    "        ('putri', 'putri malu'),\n",
    "        ('raja', 'rajagaluh')\n",
    "    ])\n",
    "\n",
    "    for character in characters_list:\n",
    "        character = normalize(character)\n",
    "        found = False\n",
    "        for key, cluster in aliases_clusters.items():\n",
    "            for name in cluster:\n",
    "                name = normalize(name)\n",
    "\n",
    "                # ‚ùó Skip similarity merging if either alias is too short\n",
    "                if len(character) < 4 or len(name) < 4:\n",
    "                    if character != name:\n",
    "                        if f\" {character} \" in f\" {name} \" or f\" {name} \" in f\" {character} \":\n",
    "                            cluster.add(character)\n",
    "                            found = True\n",
    "                            break\n",
    "                        continue\n",
    "\n",
    "                if character.endswith(\"nya\") and name.endswith(\"nya\"):\n",
    "                    if compute_similarity(character[:-3], name[:-3])['jaro'] >= threshold:\n",
    "                        cluster.add(character)\n",
    "                        found = True\n",
    "                        break\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                if f\" {character} \" in f\" {name} \" or f\" {name} \" in f\" {character} \":\n",
    "                    cluster.add(character)\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "                char_norm = normalize(character)\n",
    "                name_norm = normalize(name)\n",
    "\n",
    "                if (char_norm, name_norm) in false_merge_blacklist or (name_norm, char_norm) in false_merge_blacklist:\n",
    "                    continue\n",
    "\n",
    "                if compute_similarity(character, name)['jaro'] >= threshold:\n",
    "                    if character in name or name in character:\n",
    "                        continue\n",
    "                    cluster.add(character)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if not found:\n",
    "            aliases_clusters[f\"person-{cluster_id}\"] = {character}\n",
    "            cluster_id += 1\n",
    "    return aliases_clusters\n",
    "\n",
    "# Cluster characters with pointers\n",
    "def cluster_with_pointers(characters_with_pointer, pointers, threshold):\n",
    "    all_pointer_item_clusters = []\n",
    "    for p in pointers:\n",
    "        pointer_cluster = {}\n",
    "        pointer_cluster_id = 1\n",
    "        one_token_list = []\n",
    "        character_per_pointer = [\n",
    "            character for character in characters_with_pointer\n",
    "            if normalize(character).startswith(p.lower())\n",
    "        ]\n",
    "        for character in character_per_pointer:\n",
    "            character = normalize(character)\n",
    "            tokens = character.split()\n",
    "            if len(tokens) == 1:\n",
    "                one_token_list.append(character)\n",
    "            else:\n",
    "                found = False\n",
    "                for key, cluster in pointer_cluster.items():\n",
    "                    for name in cluster:\n",
    "                        name = normalize(name)\n",
    "                        # Check exclusion\n",
    "                        if is_excluded(character, name):\n",
    "                            continue\n",
    "                        # Suffix match\n",
    "                        if character.endswith(\"nya\") and character[:-3] in name:\n",
    "                            cluster.append(character)\n",
    "                            found = True\n",
    "                            break\n",
    "                        # Compare suffix after pointer\n",
    "                        suffix_char = character[len(p):].strip()\n",
    "                        suffix_name = name[len(p):].strip()\n",
    "\n",
    "                        if len(suffix_char) < 4 or len(suffix_name) < 4:\n",
    "                            if suffix_char != suffix_name:\n",
    "                                continue  # prevent false merge for short suffixes\n",
    "\n",
    "                        if suffix_char in suffix_name or compute_similarity(suffix_char, suffix_name)['jaccard'] >= threshold:\n",
    "                            cluster.append(character)\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    pointer_cluster[pointer_cluster_id] = [character]\n",
    "                    pointer_cluster_id += 1\n",
    "        if one_token_list:\n",
    "            if len(pointer_cluster) == 1:\n",
    "                for item in one_token_list:\n",
    "                    pointer_cluster[1].append(item)\n",
    "            elif not pointer_cluster:\n",
    "                pointer_cluster[pointer_cluster_id] = one_token_list\n",
    "        all_pointer_item_clusters.extend(pointer_cluster.values())\n",
    "    return all_pointer_item_clusters\n",
    "\n",
    "# Merge the two types of clusters\n",
    "def merge_clusters(aliases_clusters, pointer_clusters):\n",
    "    final_clusters = {}\n",
    "    counter = 1\n",
    "    for cluster in pointer_clusters:\n",
    "        final_clusters[f\"Tokoh-{counter}\"] = list(set(cluster))\n",
    "        counter += 1\n",
    "    for key, value in aliases_clusters.items():\n",
    "        final_clusters[f\"Tokoh-{counter}\"] = list(set(value))\n",
    "        counter += 1\n",
    "    return final_clusters\n",
    "\n",
    "# Main clustering per story\n",
    "def cluster_character_aliases(characters_list, pointers):\n",
    "    aliases_clusters = {}\n",
    "    characters_with_pointer = [\n",
    "        character for character in characters_list\n",
    "        if any(normalize(character).startswith(pointer.lower()) for pointer in pointers)\n",
    "    ]\n",
    "    characters_without_pointer = [char for char in characters_list if char not in characters_with_pointer]\n",
    "\n",
    "    aliases_clusters = cluster_without_pointers(characters_without_pointer, aliases_clusters, 0.82)\n",
    "    pointer_clusters = cluster_with_pointers(characters_with_pointer, pointers, 0.75)  # raised threshold\n",
    "    return merge_clusters(aliases_clusters, pointer_clusters)\n",
    "\n",
    "# Run on all stories\n",
    "all_results = []\n",
    "grouped = df.groupby(\"story_id\")['normalized_characters'].apply(lambda x: sum(x, []))\n",
    "\n",
    "for story_id, characters in grouped.items():\n",
    "    sorted_characters = sorted(set(characters), key=len, reverse=True)\n",
    "    result = cluster_character_aliases(sorted_characters, POINTERS)\n",
    "    for person, aliases in result.items():\n",
    "        all_results.append({\n",
    "            'story_id': story_id,\n",
    "            'person': person,\n",
    "            'aliases': aliases\n",
    "        })\n",
    "\n",
    "# Save results\n",
    "df_result = pd.DataFrame(all_results)\n",
    "df_result.to_csv(\"alias_clusters_all.csv\", index=False)\n",
    "print(\"‚úÖ Alias clustering complete with exclusion logic! Saved as alias_clusters_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d2112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
