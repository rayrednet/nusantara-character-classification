{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1d49f2",
   "metadata": {},
   "source": [
    "# post preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a46e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_aliases = [\n",
    "    'puterinya', 'Puteri Ayu', 'permaisurilah', 'ayahnya', 'Pak Gendut',\n",
    "    'Istriku', 'Doyan Nada', 'Allah', 'karyawannya', 'Nabilah',\n",
    "    'petani', 'Petani', 'ikan', 'Pak', 'gadis', 'Puteri', 'desa', \n",
    "    'penduduk desa', 'bidadari', 'suami', 'Putera', 'ayahnya', \n",
    "    'istri petani', 'suaminya', 'istrinya', 'Kanda', 'ayah'\n",
    "]\n",
    "\n",
    "\n",
    "EXCEPTIONS = {'allah', 'nabilah', 'kahlil', 'permaisuri', 'istri', 'puteri', 'karyawan'}\n",
    "\n",
    "def normalize_alias_custom(name):\n",
    "    name = name.lower().strip()\n",
    "    if name in EXCEPTIONS:\n",
    "        return name\n",
    "\n",
    "    # Possessive\n",
    "    for suffix in ['nya', 'ku', 'mu']:\n",
    "        if name.endswith(suffix) and len(name) > len(suffix) + 2:\n",
    "            name = name[:-len(suffix)]\n",
    "\n",
    "    # Emphatic particles\n",
    "    for suffix in ['lah', 'kah', 'tah', 'nda']:\n",
    "        if name.endswith(suffix) and len(name) > len(suffix) + 2:\n",
    "            name = name[:-len(suffix)]\n",
    "\n",
    "    return name.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7de642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def normalize_alias_stem(name):\n",
    "    return stemmer.stem(name.lower().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aeea186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puterinya                 | Custom → puteri          | Stemmer → puter\n",
      "Puteri Ayu                | Custom → puteri ayu      | Stemmer → puter ayu\n",
      "permaisurilah             | Custom → permaisuri      | Stemmer → permaisuri\n",
      "ayahnya                   | Custom → ayah            | Stemmer → ayah\n",
      "Pak Gendut                | Custom → pak gendut      | Stemmer → pak gendut\n",
      "Istriku                   | Custom → istri           | Stemmer → istri\n",
      "Doyan Nada                | Custom → doyan nada      | Stemmer → doyan nada\n",
      "Allah                     | Custom → allah           | Stemmer → allah\n",
      "karyawannya               | Custom → karyawan        | Stemmer → karyawannya\n",
      "Nabilah                   | Custom → nabilah         | Stemmer → nabi\n",
      "petani                    | Custom → petani          | Stemmer → tani\n",
      "Petani                    | Custom → petani          | Stemmer → tani\n",
      "ikan                      | Custom → ikan            | Stemmer → ikan\n",
      "Pak                       | Custom → pak             | Stemmer → pak\n",
      "gadis                     | Custom → gadis           | Stemmer → gadis\n",
      "Puteri                    | Custom → puteri          | Stemmer → puter\n",
      "desa                      | Custom → desa            | Stemmer → desa\n",
      "penduduk desa             | Custom → penduduk desa   | Stemmer → duduk desa\n",
      "bidadari                  | Custom → bidadari        | Stemmer → bidadari\n",
      "suami                     | Custom → suami           | Stemmer → suami\n",
      "Putera                    | Custom → putera          | Stemmer → putera\n",
      "ayahnya                   | Custom → ayah            | Stemmer → ayah\n",
      "istri petani              | Custom → istri petani    | Stemmer → istri tani\n",
      "suaminya                  | Custom → suami           | Stemmer → suami\n",
      "istrinya                  | Custom → istri           | Stemmer → istri\n",
      "Kanda                     | Custom → kanda           | Stemmer → kanda\n",
      "ayah                      | Custom → ayah            | Stemmer → ayah\n"
     ]
    }
   ],
   "source": [
    "for alias in sample_aliases:\n",
    "    custom = normalize_alias_custom(alias)\n",
    "    stemmed = normalize_alias_stem(alias)\n",
    "    print(f\"{alias:<25} | Custom → {custom:<15} | Stemmer → {stemmed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8412c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      story_id  sentence_id               characters    normalized_characters\n",
      "0            1            0                 [petani]                 [petani]\n",
      "1            1            3                 [petani]                 [petani]\n",
      "2            1           12                 [Petani]                 [petani]\n",
      "3            1           13                   [ikan]                   [ikan]\n",
      "4            1           15                 [petani]                 [petani]\n",
      "...        ...          ...                      ...                      ...\n",
      "5582       111          188          [tikus, anjing]          [tikus, anjing]\n",
      "5583       111          189              [anak raja]              [anak raja]\n",
      "5584       111          192  [kucing, anjing, tikus]  [kucing, anjing, tikus]\n",
      "5585       111          193  [kucing, anjing, tikus]  [kucing, anjing, tikus]\n",
      "8813        10           66              [mataniari]              [mataniari]\n",
      "\n",
      "[1190 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"pseudo_characters_final.csv\")\n",
    "\n",
    "# Convert stringified list to Python list\n",
    "df['characters'] = df['characters'].apply(ast.literal_eval)\n",
    "\n",
    "# Define target story IDs\n",
    "target_story_ids = [1, 7, 10, 111, 87, 109, 16, 23, 35, 25, 26]\n",
    "\n",
    "# Filter only the relevant story IDs\n",
    "df = df[df['story_id'].isin(target_story_ids)].copy()\n",
    "\n",
    "# Define custom normalization function\n",
    "EXCEPTIONS = {'allah', 'nabilah', 'kahlil', 'permaisuri', 'istri', 'puteri', 'karyawan'}\n",
    "\n",
    "def normalize_alias_custom(name):\n",
    "    name = name.lower().strip()\n",
    "    if name in EXCEPTIONS:\n",
    "        return name\n",
    "\n",
    "    tokens = name.split()\n",
    "\n",
    "    # Strip possessive only if the word is a single token\n",
    "    if len(tokens) == 1:\n",
    "        for suffix in ['nya', 'ku', 'mu']:\n",
    "            if name.endswith(suffix) and len(name) > len(suffix) + 2:\n",
    "                name = name[:-len(suffix)]\n",
    "    # Don't strip possessive suffix from multi-word names like \"kepala suku\"\n",
    "\n",
    "    # Emphatic particles (optional for multi-word too)\n",
    "    for suffix in ['lah', 'kah', 'tah', 'nda']:\n",
    "        if name.endswith(suffix) and len(name) > len(suffix) + 2:\n",
    "            name = name[:-len(suffix)]\n",
    "\n",
    "    return name.strip()\n",
    "\n",
    "# Apply normalization to each character\n",
    "df['normalized_characters'] = df['characters'].apply(\n",
    "    lambda char_list: [normalize_alias_custom(char) for char in char_list]\n",
    ")\n",
    "\n",
    "# Show only the required columns\n",
    "df = df[['story_id', 'sentence_id', 'characters', 'normalized_characters']]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b9c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"normalized_characters_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21264b3",
   "metadata": {},
   "source": [
    "## normalized all story id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad496d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All stories processed and saved as normalized_characters_all.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"pseudo_characters_final.csv\")\n",
    "\n",
    "# Convert stringified list to Python list\n",
    "df['characters'] = df['characters'].apply(ast.literal_eval)\n",
    "\n",
    "# Updated exceptions\n",
    "EXCEPTIONS = {'allah', 'nabilah', 'kahlil', 'permaisuri', 'istri', 'puteri', 'karyawan'}\n",
    "\n",
    "# Improved normalization function\n",
    "def normalize_alias_custom(name):\n",
    "    name = name.lower().strip()\n",
    "    if name in EXCEPTIONS:\n",
    "        return name\n",
    "\n",
    "    tokens = name.split()\n",
    "\n",
    "    # Strip possessive only if it's a single token\n",
    "    if len(tokens) == 1:\n",
    "        for suffix in ['nya', 'ku', 'mu']:\n",
    "            if name.endswith(suffix) and len(name) > len(suffix) + 2:\n",
    "                name = name[:-len(suffix)]\n",
    "\n",
    "    # Emphatic particles (okay for multi-word)\n",
    "    for suffix in ['lah', 'kah', 'tah', 'nda']:\n",
    "        if name.endswith(suffix) and len(name) > len(suffix) + 2:\n",
    "            name = name[:-len(suffix)]\n",
    "\n",
    "    return name.strip()\n",
    "\n",
    "# Apply normalization\n",
    "df['normalized_characters'] = df['characters'].apply(\n",
    "    lambda char_list: [normalize_alias_custom(char) for char in char_list]\n",
    ")\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[['story_id', 'sentence_id', 'characters', 'normalized_characters']]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"normalized_characters_all.csv\", index=False)\n",
    "\n",
    "print(\"All stories processed and saved as normalized_characters_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528178c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
