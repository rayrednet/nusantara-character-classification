{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445f89e3",
   "metadata": {},
   "source": [
    "# pseudo label with deep learning model and majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffbcd6",
   "metadata": {},
   "source": [
    "## using cahya BERT V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927702d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1025, 'grad_norm': 13.499939918518066, 'learning_rate': 1e-05, 'epoch': 0.31446540880503143}\n",
      "{'loss': 0.9453, 'grad_norm': 13.945780754089355, 'learning_rate': 2e-05, 'epoch': 0.6289308176100629}\n",
      "{'loss': 0.8313, 'grad_norm': 13.853926658630371, 'learning_rate': 1.9562363238512036e-05, 'epoch': 0.9433962264150944}\n",
      "{'eval_loss': 0.7234816551208496, 'eval_accuracy': 0.6876971608832808, 'eval_f1': 0.6796302879488091, 'eval_precision': 0.7064663160114074, 'eval_recall': 0.6932458293771245, 'eval_runtime': 0.8067, 'eval_samples_per_second': 392.957, 'eval_steps_per_second': 49.584, 'epoch': 1.0}\n",
      "{'loss': 0.5336, 'grad_norm': 16.30808448791504, 'learning_rate': 1.912472647702407e-05, 'epoch': 1.2578616352201257}\n",
      "{'loss': 0.6336, 'grad_norm': 17.6890811920166, 'learning_rate': 1.8687089715536106e-05, 'epoch': 1.5723270440251573}\n",
      "{'loss': 0.6158, 'grad_norm': 18.59699058532715, 'learning_rate': 1.824945295404814e-05, 'epoch': 1.8867924528301887}\n",
      "{'eval_loss': 0.5633793473243713, 'eval_accuracy': 0.7760252365930599, 'eval_f1': 0.7619251417022118, 'eval_precision': 0.7902897229660906, 'eval_recall': 0.7478997246642757, 'eval_runtime': 0.8093, 'eval_samples_per_second': 391.691, 'eval_steps_per_second': 49.425, 'epoch': 2.0}\n",
      "{'loss': 0.4549, 'grad_norm': 1.6865839958190918, 'learning_rate': 1.7811816192560176e-05, 'epoch': 2.20125786163522}\n",
      "{'loss': 0.472, 'grad_norm': 11.6586275100708, 'learning_rate': 1.737417943107221e-05, 'epoch': 2.5157232704402515}\n",
      "{'loss': 0.4696, 'grad_norm': 17.749805450439453, 'learning_rate': 1.6936542669584245e-05, 'epoch': 2.830188679245283}\n",
      "{'eval_loss': 0.6415837407112122, 'eval_accuracy': 0.7760252365930599, 'eval_f1': 0.7704374343841227, 'eval_precision': 0.7674600362381666, 'eval_recall': 0.7771026941576021, 'eval_runtime': 0.8467, 'eval_samples_per_second': 374.378, 'eval_steps_per_second': 47.24, 'epoch': 3.0}\n",
      "{'loss': 0.4379, 'grad_norm': 6.434173107147217, 'learning_rate': 1.649890590809628e-05, 'epoch': 3.1446540880503147}\n",
      "{'loss': 0.3008, 'grad_norm': 9.09799861907959, 'learning_rate': 1.6061269146608315e-05, 'epoch': 3.459119496855346}\n",
      "{'loss': 0.4525, 'grad_norm': 11.644540786743164, 'learning_rate': 1.562363238512035e-05, 'epoch': 3.7735849056603774}\n",
      "{'eval_loss': 0.6449341773986816, 'eval_accuracy': 0.7854889589905363, 'eval_f1': 0.780383361568869, 'eval_precision': 0.77560173743516, 'eval_recall': 0.7862686351777056, 'eval_runtime': 0.7766, 'eval_samples_per_second': 408.181, 'eval_steps_per_second': 51.506, 'epoch': 4.0}\n",
      "{'loss': 0.421, 'grad_norm': 7.034635066986084, 'learning_rate': 1.5185995623632386e-05, 'epoch': 4.088050314465409}\n",
      "{'loss': 0.2713, 'grad_norm': 21.84261131286621, 'learning_rate': 1.4748358862144421e-05, 'epoch': 4.40251572327044}\n",
      "{'loss': 0.3445, 'grad_norm': 1.2943397760391235, 'learning_rate': 1.4310722100656456e-05, 'epoch': 4.716981132075472}\n",
      "{'eval_loss': 0.7947801947593689, 'eval_accuracy': 0.7823343848580442, 'eval_f1': 0.7731371969248966, 'eval_precision': 0.7719233728340341, 'eval_recall': 0.7777081375727491, 'eval_runtime': 0.7511, 'eval_samples_per_second': 422.039, 'eval_steps_per_second': 53.254, 'epoch': 5.0}\n",
      "{'loss': 0.4093, 'grad_norm': 3.322532892227173, 'learning_rate': 1.387308533916849e-05, 'epoch': 5.031446540880503}\n",
      "{'loss': 0.2718, 'grad_norm': 1.4810527563095093, 'learning_rate': 1.3435448577680525e-05, 'epoch': 5.345911949685535}\n",
      "{'loss': 0.2999, 'grad_norm': 16.526201248168945, 'learning_rate': 1.299781181619256e-05, 'epoch': 5.660377358490566}\n",
      "{'loss': 0.3426, 'grad_norm': 6.313784122467041, 'learning_rate': 1.2560175054704595e-05, 'epoch': 5.9748427672955975}\n",
      "{'eval_loss': 0.9141300916671753, 'eval_accuracy': 0.7634069400630915, 'eval_f1': 0.7581723859678487, 'eval_precision': 0.7527009266684487, 'eval_recall': 0.7656182918689868, 'eval_runtime': 0.7376, 'eval_samples_per_second': 429.749, 'eval_steps_per_second': 54.227, 'epoch': 6.0}\n",
      "{'train_runtime': 106.7501, 'train_samples_per_second': 178.173, 'train_steps_per_second': 22.342, 'train_loss': 0.5056282294371343, 'epoch': 6.0}\n",
      "\n",
      "📚 Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0922, 'grad_norm': 13.378011703491211, 'learning_rate': 1e-05, 'epoch': 0.31446540880503143}\n",
      "{'loss': 1.0266, 'grad_norm': 12.59664535522461, 'learning_rate': 2e-05, 'epoch': 0.6289308176100629}\n",
      "{'loss': 0.8219, 'grad_norm': 13.720168113708496, 'learning_rate': 1.9562363238512036e-05, 'epoch': 0.9433962264150944}\n",
      "{'eval_loss': 0.8257413506507874, 'eval_accuracy': 0.6813880126182965, 'eval_f1': 0.6792773637601224, 'eval_precision': 0.7032581323606295, 'eval_recall': 0.709226780539881, 'eval_runtime': 0.7524, 'eval_samples_per_second': 421.345, 'eval_steps_per_second': 53.167, 'epoch': 1.0}\n",
      "{'loss': 0.6749, 'grad_norm': 16.093263626098633, 'learning_rate': 1.912472647702407e-05, 'epoch': 1.2578616352201257}\n",
      "{'loss': 0.565, 'grad_norm': 27.511260986328125, 'learning_rate': 1.8687089715536106e-05, 'epoch': 1.5723270440251573}\n",
      "{'loss': 0.5453, 'grad_norm': 13.385172843933105, 'learning_rate': 1.824945295404814e-05, 'epoch': 1.8867924528301887}\n",
      "{'eval_loss': 0.7477670907974243, 'eval_accuracy': 0.7192429022082019, 'eval_f1': 0.702061667578909, 'eval_precision': 0.7152978211658177, 'eval_recall': 0.7021346308057875, 'eval_runtime': 0.6756, 'eval_samples_per_second': 469.192, 'eval_steps_per_second': 59.204, 'epoch': 2.0}\n",
      "{'loss': 0.4086, 'grad_norm': 16.605648040771484, 'learning_rate': 1.7811816192560176e-05, 'epoch': 2.20125786163522}\n",
      "{'loss': 0.432, 'grad_norm': 23.95891571044922, 'learning_rate': 1.737417943107221e-05, 'epoch': 2.5157232704402515}\n",
      "{'loss': 0.3998, 'grad_norm': 10.646124839782715, 'learning_rate': 1.6936542669584245e-05, 'epoch': 2.830188679245283}\n",
      "{'eval_loss': 0.9551194310188293, 'eval_accuracy': 0.7287066246056783, 'eval_f1': 0.6968520805436101, 'eval_precision': 0.7234299516908212, 'eval_recall': 0.6835564389038392, 'eval_runtime': 0.6475, 'eval_samples_per_second': 489.582, 'eval_steps_per_second': 61.777, 'epoch': 3.0}\n",
      "{'loss': 0.4465, 'grad_norm': 10.292492866516113, 'learning_rate': 1.649890590809628e-05, 'epoch': 3.1446540880503147}\n",
      "{'loss': 0.3123, 'grad_norm': 10.095549583435059, 'learning_rate': 1.6061269146608315e-05, 'epoch': 3.459119496855346}\n",
      "{'loss': 0.4587, 'grad_norm': 10.451650619506836, 'learning_rate': 1.562363238512035e-05, 'epoch': 3.7735849056603774}\n",
      "{'eval_loss': 0.7927022576332092, 'eval_accuracy': 0.7381703470031545, 'eval_f1': 0.7232861919762877, 'eval_precision': 0.7276894869633831, 'eval_recall': 0.7216865830000279, 'eval_runtime': 0.6568, 'eval_samples_per_second': 482.655, 'eval_steps_per_second': 60.903, 'epoch': 4.0}\n",
      "{'loss': 0.327, 'grad_norm': 5.727385997772217, 'learning_rate': 1.5185995623632386e-05, 'epoch': 4.088050314465409}\n",
      "{'loss': 0.3268, 'grad_norm': 15.661779403686523, 'learning_rate': 1.4748358862144421e-05, 'epoch': 4.40251572327044}\n",
      "{'loss': 0.3217, 'grad_norm': 8.067978858947754, 'learning_rate': 1.4310722100656456e-05, 'epoch': 4.716981132075472}\n",
      "{'eval_loss': 1.1413192749023438, 'eval_accuracy': 0.7255520504731862, 'eval_f1': 0.7181432904729793, 'eval_precision': 0.7145913114806981, 'eval_recall': 0.726753153897747, 'eval_runtime': 0.6629, 'eval_samples_per_second': 478.214, 'eval_steps_per_second': 60.342, 'epoch': 5.0}\n",
      "{'loss': 0.2548, 'grad_norm': 0.0663004070520401, 'learning_rate': 1.387308533916849e-05, 'epoch': 5.031446540880503}\n",
      "{'loss': 0.2469, 'grad_norm': 6.491139888763428, 'learning_rate': 1.3435448577680525e-05, 'epoch': 5.345911949685535}\n",
      "{'loss': 0.3694, 'grad_norm': 19.434099197387695, 'learning_rate': 1.299781181619256e-05, 'epoch': 5.660377358490566}\n",
      "{'loss': 0.2959, 'grad_norm': 0.8603255152702332, 'learning_rate': 1.2560175054704595e-05, 'epoch': 5.9748427672955975}\n",
      "{'eval_loss': 1.0842841863632202, 'eval_accuracy': 0.7413249211356467, 'eval_f1': 0.7281579592474928, 'eval_precision': 0.7302916038210155, 'eval_recall': 0.7275681738796754, 'eval_runtime': 0.6561, 'eval_samples_per_second': 483.141, 'eval_steps_per_second': 60.964, 'epoch': 6.0}\n",
      "{'loss': 0.1649, 'grad_norm': 1.0867643356323242, 'learning_rate': 1.212253829321663e-05, 'epoch': 6.289308176100629}\n",
      "{'loss': 0.2847, 'grad_norm': 2.6115880012512207, 'learning_rate': 1.1684901531728665e-05, 'epoch': 6.60377358490566}\n",
      "{'loss': 0.3163, 'grad_norm': 21.316162109375, 'learning_rate': 1.12472647702407e-05, 'epoch': 6.918238993710692}\n",
      "{'eval_loss': 1.1468783617019653, 'eval_accuracy': 0.7570977917981072, 'eval_f1': 0.7437110093447409, 'eval_precision': 0.7508886626669894, 'eval_recall': 0.7385242070773907, 'eval_runtime': 0.6691, 'eval_samples_per_second': 473.791, 'eval_steps_per_second': 59.784, 'epoch': 7.0}\n",
      "{'loss': 0.2074, 'grad_norm': 0.23576316237449646, 'learning_rate': 1.0809628008752738e-05, 'epoch': 7.232704402515723}\n",
      "{'loss': 0.2311, 'grad_norm': 28.041034698486328, 'learning_rate': 1.0371991247264772e-05, 'epoch': 7.547169811320755}\n",
      "{'loss': 0.2567, 'grad_norm': 5.2426533699035645, 'learning_rate': 9.934354485776806e-06, 'epoch': 7.861635220125786}\n",
      "{'eval_loss': 1.4013744592666626, 'eval_accuracy': 0.7476340694006309, 'eval_f1': 0.7340799087274189, 'eval_precision': 0.7404232645585829, 'eval_recall': 0.7320725941741649, 'eval_runtime': 0.6723, 'eval_samples_per_second': 471.525, 'eval_steps_per_second': 59.498, 'epoch': 8.0}\n",
      "{'loss': 0.1669, 'grad_norm': 0.1408250629901886, 'learning_rate': 9.49671772428884e-06, 'epoch': 8.176100628930818}\n",
      "{'loss': 0.168, 'grad_norm': 0.06663255393505096, 'learning_rate': 9.059080962800875e-06, 'epoch': 8.49056603773585}\n",
      "{'loss': 0.2693, 'grad_norm': 0.3986735939979553, 'learning_rate': 8.62144420131291e-06, 'epoch': 8.80503144654088}\n",
      "{'eval_loss': 1.3750211000442505, 'eval_accuracy': 0.7570977917981072, 'eval_f1': 0.7382741475795211, 'eval_precision': 0.7570999617188248, 'eval_recall': 0.728993228938621, 'eval_runtime': 0.7007, 'eval_samples_per_second': 452.383, 'eval_steps_per_second': 57.083, 'epoch': 9.0}\n",
      "{'train_runtime': 152.992, 'train_samples_per_second': 124.32, 'train_steps_per_second': 15.589, 'train_loss': 0.402226292445558, 'epoch': 9.0}\n",
      "\n",
      "📚 Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1133, 'grad_norm': 12.608789443969727, 'learning_rate': 1e-05, 'epoch': 0.31446540880503143}\n",
      "{'loss': 1.0193, 'grad_norm': 9.882536888122559, 'learning_rate': 2e-05, 'epoch': 0.6289308176100629}\n",
      "{'loss': 0.8643, 'grad_norm': 17.513830184936523, 'learning_rate': 1.9562363238512036e-05, 'epoch': 0.9433962264150944}\n",
      "{'eval_loss': 0.6597320437431335, 'eval_accuracy': 0.7160883280757098, 'eval_f1': 0.7158725511184992, 'eval_precision': 0.710200774420958, 'eval_recall': 0.7441712562286913, 'eval_runtime': 0.8207, 'eval_samples_per_second': 386.245, 'eval_steps_per_second': 48.738, 'epoch': 1.0}\n",
      "{'loss': 0.6008, 'grad_norm': 12.311951637268066, 'learning_rate': 1.912472647702407e-05, 'epoch': 1.2578616352201257}\n",
      "{'loss': 0.6823, 'grad_norm': 13.067063331604004, 'learning_rate': 1.8687089715536106e-05, 'epoch': 1.5723270440251573}\n",
      "{'loss': 0.5613, 'grad_norm': 10.773126602172852, 'learning_rate': 1.824945295404814e-05, 'epoch': 1.8867924528301887}\n",
      "{'eval_loss': 0.5385318398475647, 'eval_accuracy': 0.7823343848580442, 'eval_f1': 0.7775859864467459, 'eval_precision': 0.776719632396787, 'eval_recall': 0.778845397324941, 'eval_runtime': 0.8075, 'eval_samples_per_second': 392.551, 'eval_steps_per_second': 49.533, 'epoch': 2.0}\n",
      "{'loss': 0.4784, 'grad_norm': 7.369568824768066, 'learning_rate': 1.7811816192560176e-05, 'epoch': 2.20125786163522}\n",
      "{'loss': 0.4525, 'grad_norm': 6.711803913116455, 'learning_rate': 1.737417943107221e-05, 'epoch': 2.5157232704402515}\n",
      "{'loss': 0.4062, 'grad_norm': 8.746513366699219, 'learning_rate': 1.6936542669584245e-05, 'epoch': 2.830188679245283}\n",
      "{'eval_loss': 0.6204754710197449, 'eval_accuracy': 0.7697160883280757, 'eval_f1': 0.7578406647590411, 'eval_precision': 0.7708215212915163, 'eval_recall': 0.7575531077891423, 'eval_runtime': 0.8356, 'eval_samples_per_second': 379.373, 'eval_steps_per_second': 47.87, 'epoch': 3.0}\n",
      "{'loss': 0.4512, 'grad_norm': 7.270471572875977, 'learning_rate': 1.649890590809628e-05, 'epoch': 3.1446540880503147}\n",
      "{'loss': 0.3522, 'grad_norm': 6.263185501098633, 'learning_rate': 1.6061269146608315e-05, 'epoch': 3.459119496855346}\n",
      "{'loss': 0.3999, 'grad_norm': 28.370038986206055, 'learning_rate': 1.562363238512035e-05, 'epoch': 3.7735849056603774}\n",
      "{'eval_loss': 0.6825670599937439, 'eval_accuracy': 0.7917981072555205, 'eval_f1': 0.7869326093010304, 'eval_precision': 0.7832033307066331, 'eval_recall': 0.7912437713086807, 'eval_runtime': 0.82, 'eval_samples_per_second': 386.582, 'eval_steps_per_second': 48.78, 'epoch': 4.0}\n",
      "{'loss': 0.3353, 'grad_norm': 0.9752659201622009, 'learning_rate': 1.5185995623632386e-05, 'epoch': 4.088050314465409}\n",
      "{'loss': 0.2768, 'grad_norm': 29.079484939575195, 'learning_rate': 1.4748358862144421e-05, 'epoch': 4.40251572327044}\n",
      "{'loss': 0.2714, 'grad_norm': 10.99722957611084, 'learning_rate': 1.4310722100656456e-05, 'epoch': 4.716981132075472}\n",
      "{'eval_loss': 0.6302933096885681, 'eval_accuracy': 0.7981072555205048, 'eval_f1': 0.7964115234049051, 'eval_precision': 0.788714525635677, 'eval_recall': 0.8077432467873066, 'eval_runtime': 0.8242, 'eval_samples_per_second': 384.596, 'eval_steps_per_second': 48.529, 'epoch': 5.0}\n",
      "{'loss': 0.3821, 'grad_norm': 2.324814796447754, 'learning_rate': 1.387308533916849e-05, 'epoch': 5.031446540880503}\n",
      "{'loss': 0.2557, 'grad_norm': 3.93510103225708, 'learning_rate': 1.3435448577680525e-05, 'epoch': 5.345911949685535}\n",
      "{'loss': 0.2703, 'grad_norm': 1.0143964290618896, 'learning_rate': 1.299781181619256e-05, 'epoch': 5.660377358490566}\n",
      "{'loss': 0.4057, 'grad_norm': 11.36970043182373, 'learning_rate': 1.2560175054704595e-05, 'epoch': 5.9748427672955975}\n",
      "{'eval_loss': 0.8511558771133423, 'eval_accuracy': 0.804416403785489, 'eval_f1': 0.8026072124756336, 'eval_precision': 0.7932133891386863, 'eval_recall': 0.819499082087595, 'eval_runtime': 0.8161, 'eval_samples_per_second': 388.42, 'eval_steps_per_second': 49.012, 'epoch': 6.0}\n",
      "{'loss': 0.2213, 'grad_norm': 21.81884002685547, 'learning_rate': 1.212253829321663e-05, 'epoch': 6.289308176100629}\n",
      "{'loss': 0.2445, 'grad_norm': 5.204938888549805, 'learning_rate': 1.1684901531728665e-05, 'epoch': 6.60377358490566}\n",
      "{'loss': 0.337, 'grad_norm': 13.473462104797363, 'learning_rate': 1.12472647702407e-05, 'epoch': 6.918238993710692}\n",
      "{'eval_loss': 0.7320745587348938, 'eval_accuracy': 0.7981072555205048, 'eval_f1': 0.7947519550485599, 'eval_precision': 0.7868982175578877, 'eval_recall': 0.8074383687385261, 'eval_runtime': 0.8253, 'eval_samples_per_second': 384.107, 'eval_steps_per_second': 48.468, 'epoch': 7.0}\n",
      "{'loss': 0.1897, 'grad_norm': 7.6354241371154785, 'learning_rate': 1.0809628008752738e-05, 'epoch': 7.232704402515723}\n",
      "{'loss': 0.2745, 'grad_norm': 12.016064643859863, 'learning_rate': 1.0371991247264772e-05, 'epoch': 7.547169811320755}\n",
      "{'loss': 0.245, 'grad_norm': 0.3059503734111786, 'learning_rate': 9.934354485776806e-06, 'epoch': 7.861635220125786}\n",
      "{'eval_loss': 0.7738870978355408, 'eval_accuracy': 0.7823343848580442, 'eval_f1': 0.7745446453084268, 'eval_precision': 0.7714538405782646, 'eval_recall': 0.7814712824547599, 'eval_runtime': 0.8266, 'eval_samples_per_second': 383.52, 'eval_steps_per_second': 48.394, 'epoch': 8.0}\n",
      "{'train_runtime': 136.9713, 'train_samples_per_second': 138.861, 'train_steps_per_second': 17.412, 'train_loss': 0.4429460621479922, 'epoch': 8.0}\n",
      "\n",
      "📚 Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.116, 'grad_norm': 13.018996238708496, 'learning_rate': 1e-05, 'epoch': 0.31446540880503143}\n",
      "{'loss': 0.9957, 'grad_norm': 13.158970832824707, 'learning_rate': 2e-05, 'epoch': 0.6289308176100629}\n",
      "{'loss': 0.8097, 'grad_norm': 11.582206726074219, 'learning_rate': 1.9562363238512036e-05, 'epoch': 0.9433962264150944}\n",
      "{'eval_loss': 0.7650182843208313, 'eval_accuracy': 0.6971608832807571, 'eval_f1': 0.6788452182963943, 'eval_precision': 0.6767173892238492, 'eval_recall': 0.681372934697089, 'eval_runtime': 0.8142, 'eval_samples_per_second': 389.343, 'eval_steps_per_second': 49.128, 'epoch': 1.0}\n",
      "{'loss': 0.5562, 'grad_norm': 12.04000186920166, 'learning_rate': 1.912472647702407e-05, 'epoch': 1.2578616352201257}\n",
      "{'loss': 0.4676, 'grad_norm': 35.731651306152344, 'learning_rate': 1.8687089715536106e-05, 'epoch': 1.5723270440251573}\n",
      "{'loss': 0.6585, 'grad_norm': 10.262194633483887, 'learning_rate': 1.824945295404814e-05, 'epoch': 1.8867924528301887}\n",
      "{'eval_loss': 0.7402867674827576, 'eval_accuracy': 0.7476340694006309, 'eval_f1': 0.7190256959058448, 'eval_precision': 0.738355700117208, 'eval_recall': 0.7092250196695516, 'eval_runtime': 0.8132, 'eval_samples_per_second': 389.797, 'eval_steps_per_second': 49.186, 'epoch': 2.0}\n",
      "{'loss': 0.4829, 'grad_norm': 4.648221492767334, 'learning_rate': 1.7811816192560176e-05, 'epoch': 2.20125786163522}\n",
      "{'loss': 0.3656, 'grad_norm': 3.88594651222229, 'learning_rate': 1.737417943107221e-05, 'epoch': 2.5157232704402515}\n",
      "{'loss': 0.4946, 'grad_norm': 26.217329025268555, 'learning_rate': 1.6936542669584245e-05, 'epoch': 2.830188679245283}\n",
      "{'eval_loss': 0.7482185363769531, 'eval_accuracy': 0.7791798107255521, 'eval_f1': 0.7639788743411827, 'eval_precision': 0.7736369910282953, 'eval_recall': 0.7591594544977708, 'eval_runtime': 0.8334, 'eval_samples_per_second': 380.391, 'eval_steps_per_second': 47.999, 'epoch': 3.0}\n",
      "{'loss': 0.3217, 'grad_norm': 8.4684419631958, 'learning_rate': 1.649890590809628e-05, 'epoch': 3.1446540880503147}\n",
      "{'loss': 0.3338, 'grad_norm': 4.180506229400635, 'learning_rate': 1.6061269146608315e-05, 'epoch': 3.459119496855346}\n",
      "{'loss': 0.4268, 'grad_norm': 16.815153121948242, 'learning_rate': 1.562363238512035e-05, 'epoch': 3.7735849056603774}\n",
      "{'eval_loss': 0.8443708419799805, 'eval_accuracy': 0.7697160883280757, 'eval_f1': 0.7538930913759669, 'eval_precision': 0.7536632292729853, 'eval_recall': 0.7542158405455023, 'eval_runtime': 0.8339, 'eval_samples_per_second': 380.137, 'eval_steps_per_second': 47.967, 'epoch': 4.0}\n",
      "{'loss': 0.3653, 'grad_norm': 9.037887573242188, 'learning_rate': 1.5185995623632386e-05, 'epoch': 4.088050314465409}\n",
      "{'loss': 0.3045, 'grad_norm': 3.6460089683532715, 'learning_rate': 1.4748358862144421e-05, 'epoch': 4.40251572327044}\n",
      "{'loss': 0.3494, 'grad_norm': 10.230002403259277, 'learning_rate': 1.4310722100656456e-05, 'epoch': 4.716981132075472}\n",
      "{'eval_loss': 0.9426818490028381, 'eval_accuracy': 0.7728706624605678, 'eval_f1': 0.755737744654286, 'eval_precision': 0.7569816674513566, 'eval_recall': 0.7545535011801731, 'eval_runtime': 0.8195, 'eval_samples_per_second': 386.821, 'eval_steps_per_second': 48.81, 'epoch': 5.0}\n",
      "{'train_runtime': 85.7126, 'train_samples_per_second': 221.904, 'train_steps_per_second': 27.826, 'train_loss': 0.5274116384158345, 'epoch': 5.0}\n",
      "\n",
      "📚 Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1107, 'grad_norm': 13.523436546325684, 'learning_rate': 1e-05, 'epoch': 0.31446540880503143}\n",
      "{'loss': 0.9937, 'grad_norm': 7.409126281738281, 'learning_rate': 2e-05, 'epoch': 0.6289308176100629}\n",
      "{'loss': 0.86, 'grad_norm': 11.293376922607422, 'learning_rate': 1.9562363238512036e-05, 'epoch': 0.9433962264150944}\n",
      "{'eval_loss': 0.6855285167694092, 'eval_accuracy': 0.7192429022082019, 'eval_f1': 0.7139936218008325, 'eval_precision': 0.7145242494079703, 'eval_recall': 0.7305992656700759, 'eval_runtime': 0.7021, 'eval_samples_per_second': 451.475, 'eval_steps_per_second': 56.968, 'epoch': 1.0}\n",
      "{'loss': 0.6477, 'grad_norm': 7.500432968139648, 'learning_rate': 1.912472647702407e-05, 'epoch': 1.2578616352201257}\n",
      "{'loss': 0.5433, 'grad_norm': 20.39215660095215, 'learning_rate': 1.8687089715536106e-05, 'epoch': 1.5723270440251573}\n",
      "{'loss': 0.6107, 'grad_norm': 16.13271141052246, 'learning_rate': 1.824945295404814e-05, 'epoch': 1.8867924528301887}\n",
      "{'eval_loss': 0.6791315078735352, 'eval_accuracy': 0.7602523659305994, 'eval_f1': 0.7501413077449944, 'eval_precision': 0.7529247042617478, 'eval_recall': 0.760572383949646, 'eval_runtime': 0.6594, 'eval_samples_per_second': 480.748, 'eval_steps_per_second': 60.662, 'epoch': 2.0}\n",
      "{'loss': 0.5017, 'grad_norm': 2.690279006958008, 'learning_rate': 1.7811816192560176e-05, 'epoch': 2.20125786163522}\n",
      "{'loss': 0.4186, 'grad_norm': 7.625307559967041, 'learning_rate': 1.737417943107221e-05, 'epoch': 2.5157232704402515}\n",
      "{'loss': 0.4592, 'grad_norm': 11.781144142150879, 'learning_rate': 1.6936542669584245e-05, 'epoch': 2.830188679245283}\n",
      "{'eval_loss': 0.8854843974113464, 'eval_accuracy': 0.7413249211356467, 'eval_f1': 0.7283066180413872, 'eval_precision': 0.7326032370810794, 'eval_recall': 0.7319466299501705, 'eval_runtime': 0.6788, 'eval_samples_per_second': 466.968, 'eval_steps_per_second': 58.923, 'epoch': 3.0}\n",
      "{'loss': 0.4362, 'grad_norm': 2.181104898452759, 'learning_rate': 1.649890590809628e-05, 'epoch': 3.1446540880503147}\n",
      "{'loss': 0.256, 'grad_norm': 1.0867611169815063, 'learning_rate': 1.6061269146608315e-05, 'epoch': 3.459119496855346}\n",
      "{'loss': 0.4917, 'grad_norm': 7.271924018859863, 'learning_rate': 1.562363238512035e-05, 'epoch': 3.7735849056603774}\n",
      "{'eval_loss': 0.8807787299156189, 'eval_accuracy': 0.7602523659305994, 'eval_f1': 0.7531643038685293, 'eval_precision': 0.7496679964598149, 'eval_recall': 0.7701448990296355, 'eval_runtime': 0.6869, 'eval_samples_per_second': 461.51, 'eval_steps_per_second': 58.235, 'epoch': 4.0}\n",
      "{'loss': 0.3598, 'grad_norm': 8.371925354003906, 'learning_rate': 1.5185995623632386e-05, 'epoch': 4.088050314465409}\n",
      "{'loss': 0.279, 'grad_norm': 11.63015079498291, 'learning_rate': 1.4748358862144421e-05, 'epoch': 4.40251572327044}\n",
      "{'loss': 0.3269, 'grad_norm': 4.161228656768799, 'learning_rate': 1.4310722100656456e-05, 'epoch': 4.716981132075472}\n",
      "{'eval_loss': 1.0439199209213257, 'eval_accuracy': 0.7476340694006309, 'eval_f1': 0.73817818545663, 'eval_precision': 0.7329237071172555, 'eval_recall': 0.7475314712824548, 'eval_runtime': 0.6803, 'eval_samples_per_second': 465.988, 'eval_steps_per_second': 58.8, 'epoch': 5.0}\n",
      "{'loss': 0.2809, 'grad_norm': 0.2685824930667877, 'learning_rate': 1.387308533916849e-05, 'epoch': 5.031446540880503}\n",
      "{'loss': 0.2588, 'grad_norm': 6.235740661621094, 'learning_rate': 1.3435448577680525e-05, 'epoch': 5.345911949685535}\n",
      "{'loss': 0.2828, 'grad_norm': 0.2901766300201416, 'learning_rate': 1.299781181619256e-05, 'epoch': 5.660377358490566}\n",
      "{'loss': 0.2841, 'grad_norm': 7.784362316131592, 'learning_rate': 1.2560175054704595e-05, 'epoch': 5.9748427672955975}\n",
      "{'eval_loss': 1.0857198238372803, 'eval_accuracy': 0.7413249211356467, 'eval_f1': 0.7349473190532794, 'eval_precision': 0.7417967186874751, 'eval_recall': 0.7397062680304223, 'eval_runtime': 0.677, 'eval_samples_per_second': 468.227, 'eval_steps_per_second': 59.082, 'epoch': 6.0}\n",
      "{'train_runtime': 102.19, 'train_samples_per_second': 186.124, 'train_steps_per_second': 23.339, 'train_loss': 0.4938793254848296, 'epoch': 6.0}\n",
      "\n",
      "✅ 5-Fold training complete. Results saved to: results/V4_CahyaBERT\n",
      "         Fold  Precision    Recall        F1  Accuracy\n",
      "0         1.0   0.775602  0.786269  0.780383  0.785489\n",
      "1         2.0   0.750889  0.738524  0.743711  0.757098\n",
      "2         3.0   0.793213  0.819499  0.802607  0.804416\n",
      "3         4.0   0.773637  0.759159  0.763979  0.779180\n",
      "4         5.0   0.749668  0.770145  0.753164  0.760252\n",
      "Average   3.0   0.768602  0.774719  0.768769  0.777287\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# === Config ===\n",
    "FOLDS = 5\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 8\n",
    "MODEL_NAME = \"cahya/bert-base-indonesian-1.5G\"\n",
    "OUTPUT_DIR = \"results/V4_CahyaBERT\"\n",
    "SEED = 42\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Seed Control ===\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_csv(\"sentence_level.csv\")\n",
    "df[\"bert_context_filtered\"] = df[\"bert_context_filtered\"].fillna(\"\")\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df[\"type\"])\n",
    "texts = df[\"bert_context_filtered\"].tolist()\n",
    "\n",
    "# Compute Class Weights\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# === Normalize Numeric Features ===\n",
    "to_scale = [\"mention_count\", \"word_count\"]\n",
    "scaler = StandardScaler()\n",
    "df[to_scale] = scaler.fit_transform(df[to_scale])\n",
    "numeric_cols = [\"mention_count\", \"word_count\", \"is_primary_in_sentence\"]\n",
    "\n",
    "# === Dataset Class ===\n",
    "class SentenceWithNumericDataset(Dataset):\n",
    "    def __init__(self, texts, labels, numeric_feats, tokenizer, max_len=128):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_len)\n",
    "        self.labels = labels\n",
    "        self.numeric_feats = torch.tensor(numeric_feats, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        item[\"numeric_feats\"] = self.numeric_feats[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# === Custom Model ===\n",
    "class IndoBERTWithNumeric(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, num_numeric_features, class_weights):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + num_numeric_features, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_feats, labels=None):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        combined = torch.cat((pooled_output, numeric_feats), dim=1)\n",
    "        logits = self.classifier(self.dropout(combined))\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "# === Custom Collator ===\n",
    "class CustomCollator:\n",
    "    def __call__(self, batch):\n",
    "        input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
    "        attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
    "        labels = torch.stack([item[\"labels\"] for item in batch])\n",
    "        numeric_feats = torch.stack([item[\"numeric_feats\"] for item in batch])\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "            \"numeric_feats\": numeric_feats\n",
    "        }\n",
    "\n",
    "# === Compute Metrics ===\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# === Cross-validation ===\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "fold_metrics = []\n",
    "cumulative_cm = np.zeros((3, 3), dtype=int)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels)):\n",
    "    print(f\"\\n📚 Fold {fold + 1}/{FOLDS}\")\n",
    "\n",
    "    train_texts = [texts[i] for i in train_idx]\n",
    "    val_texts = [texts[i] for i in val_idx]\n",
    "    train_labels = labels[train_idx]\n",
    "    val_labels = labels[val_idx]\n",
    "\n",
    "    train_numeric = df.iloc[train_idx][numeric_cols].values\n",
    "    val_numeric = df.iloc[val_idx][numeric_cols].values\n",
    "\n",
    "    train_dataset = SentenceWithNumericDataset(train_texts, train_labels, train_numeric, tokenizer)\n",
    "    val_dataset = SentenceWithNumericDataset(val_texts, val_labels, val_numeric, tokenizer)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = IndoBERTWithNumeric(MODEL_NAME, num_labels=3, num_numeric_features=3, class_weights=class_weights_tensor.to(device))\n",
    "\n",
    "    fold_dir = os.path.join(OUTPUT_DIR, f\"fold_{fold+1}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=fold_dir,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        logging_dir=os.path.join(fold_dir, \"logs\"),\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        logging_steps=50,\n",
    "        disable_tqdm=True,\n",
    "        learning_rate=2e-5,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=CustomCollator(),\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # === Save clean version of best model for inference ===\n",
    "    export_path = os.path.join(OUTPUT_DIR, f\"best_fold_{fold+1}\")\n",
    "    trainer.save_model(export_path)\n",
    "    tokenizer.save_pretrained(export_path)\n",
    "\n",
    "    # === Evaluate ===\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    preds = torch.argmax(torch.tensor(predictions.predictions), dim=1).numpy()\n",
    "    true = np.array(val_labels)\n",
    "\n",
    "    true_labels = label_encoder.inverse_transform(true)\n",
    "    pred_labels = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    report = classification_report(true_labels, pred_labels, output_dict=True, digits=4)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(os.path.join(fold_dir, \"classification_report.csv\"))\n",
    "\n",
    "    cm = confusion_matrix(true_labels, pred_labels, labels=label_encoder.classes_)\n",
    "    cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "    cumulative_cm += cm\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix - Fold {fold + 1} (IndoBERT + Numeric)\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fold_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    macro = report[\"macro avg\"]\n",
    "    fold_metrics.append({\n",
    "        \"Fold\": fold + 1,\n",
    "        \"Precision\": macro[\"precision\"],\n",
    "        \"Recall\": macro[\"recall\"],\n",
    "        \"F1\": macro[\"f1-score\"],\n",
    "        \"Accuracy\": accuracy_score(true_labels, pred_labels)\n",
    "    })\n",
    "\n",
    "# === Summary ===\n",
    "summary_df = pd.DataFrame(fold_metrics)\n",
    "summary_df.loc[\"Average\"] = summary_df.mean(numeric_only=True)\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, \"summary.csv\"), index=False)\n",
    "\n",
    "avg_cm = cumulative_cm // FOLDS\n",
    "avg_cm_df = pd.DataFrame(avg_cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(avg_cm_df, annot=True, fmt='d', cmap='Purples')\n",
    "plt.title(\"Average Confusion Matrix (5-Fold - IndoBERT + Numeric)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"average_confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✅ 5-Fold training complete. Results saved to:\", OUTPUT_DIR)\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35860ef1",
   "metadata": {},
   "source": [
    "## majority vote inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b60fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥇 Best fold is Fold 3 with F1-score = 0.8026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your summary file\n",
    "summary_path = \"results/V4_CahyaBERT/summary.csv\"\n",
    "\n",
    "# Load the summary\n",
    "summary_df = pd.read_csv(summary_path)\n",
    "\n",
    "# Drop any average rows if present\n",
    "summary_df = summary_df[summary_df[\"Fold\"] != \"Average\"]\n",
    "\n",
    "# Convert Fold to int if it's not already\n",
    "summary_df[\"Fold\"] = summary_df[\"Fold\"].astype(int)\n",
    "\n",
    "# Find the fold with the highest F1 score\n",
    "best_row = summary_df.loc[summary_df[\"F1\"].idxmax()]\n",
    "best_fold = int(best_row[\"Fold\"])\n",
    "best_f1 = best_row[\"F1\"]\n",
    "\n",
    "print(f\"🥇 Best fold is Fold {best_fold} with F1-score = {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7774fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📉 Confusion Matrix:\n",
      "             antagonist  others  protagonist\n",
      "antagonist           24       0            1\n",
      "others                1      98            5\n",
      "protagonist           6       4           52\n",
      "\n",
      "🏅 Summary (Majority Vote on Sentence Predictions):\n",
      "antagonist    precision: 0.7742  recall: 0.9600  f1-score: 0.8571  support: 25\n",
      "others        precision: 0.9608  recall: 0.9423  f1-score: 0.9515  support: 104\n",
      "protagonist   precision: 0.8966  recall: 0.8387  f1-score: 0.8667  support: 62\n",
      "\n",
      "✅ Overall Metrics:\n",
      "accuracy        : 0.9110\n",
      "macro avg f1    : 0.8918\n",
      "weighted avg f1 : 0.9116\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_DIR = \"results/V4_CahyaBERT/best_fold_3\"\n",
    "CSV_PATH = \"sentence_level.csv\"\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LABELS = [\"others\", \"protagonist\", \"antagonist\"]\n",
    "\n",
    "# === LOAD DATA ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"bert_context_filtered\"] = df[\"bert_context_filtered\"].fillna(\"\")\n",
    "scaler = StandardScaler()\n",
    "df[[\"mention_count\", \"word_count\"]] = scaler.fit_transform(df[[\"mention_count\", \"word_count\"]])\n",
    "numeric_cols = [\"mention_count\", \"word_count\", \"is_primary_in_sentence\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"type\"])\n",
    "\n",
    "# === TOKENIZER ===\n",
    "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert-base-indonesian-1.5G\")\n",
    "\n",
    "# === DATASET ===\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.encodings = tokenizer(df[\"bert_context_filtered\"].tolist(), truncation=True, padding=True, max_length=128)\n",
    "        self.numeric_feats = torch.tensor(df[numeric_cols].values, dtype=torch.float)\n",
    "        self.labels = torch.tensor(df[\"label_encoded\"].values)\n",
    "        self.metadata = df[[\"story_id\", \"person\", \"sentence_id\", \"type\"]].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"numeric_feats\"] = self.numeric_feats[idx]\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        item[\"meta\"] = self.metadata.loc[idx].to_dict()\n",
    "        return item\n",
    "\n",
    "# === CUSTOM COLLATOR ===\n",
    "def custom_collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    collated = {k: [d[k] for d in batch] for k in keys}\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"labels\", \"numeric_feats\"]:\n",
    "        collated[k] = torch.stack(collated[k])\n",
    "    return collated\n",
    "\n",
    "# === MODEL ===\n",
    "class IndoBERTWithNumeric(nn.Module):\n",
    "    def __init__(self, model_name=\"cahya/bert-base-indonesian-1.5G\", num_labels=3, num_numeric_features=3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + num_numeric_features, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_feats, labels=None):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        combined = torch.cat((pooled_output, numeric_feats), dim=1)\n",
    "        logits = self.classifier(self.dropout(combined))\n",
    "        return logits\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = IndoBERTWithNumeric()\n",
    "state_dict = load_file(os.path.join(MODEL_DIR, \"model.safetensors\"))\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# === INFERENCE ===\n",
    "dataset = SentenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=custom_collate_fn)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        numeric_feats = batch[\"numeric_feats\"].to(DEVICE)\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask, numeric_feats=numeric_feats)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            meta = batch[\"meta\"][i]\n",
    "            all_results.append({\n",
    "                \"story_id\": meta[\"story_id\"],\n",
    "                \"person\": meta[\"person\"],\n",
    "                \"sentence_id\": meta[\"sentence_id\"],\n",
    "                \"true_type\": meta[\"type\"],\n",
    "                \"predicted_type\": label_encoder.inverse_transform([preds[i]])[0],\n",
    "                \"confidence_protagonist\": probs[i][1],\n",
    "                \"confidence_antagonist\": probs[i][2],\n",
    "                \"confidence_others\": probs[i][0]\n",
    "            })\n",
    "\n",
    "# === SAVE SENTENCE-LEVEL PREDICTIONS ===\n",
    "output_dir = \"results/pseudo_vote\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pred_df = pd.DataFrame(all_results)\n",
    "pred_df.to_csv(os.path.join(output_dir, \"sentence_predictions.csv\"), index=False)\n",
    "\n",
    "# === MAJORITY VOTE PER CHARACTER ===\n",
    "agg_df = pred_df.groupby([\"story_id\", \"person\"]).agg({\n",
    "    \"predicted_type\": lambda x: x.value_counts().idxmax(),\n",
    "    \"true_type\": lambda x: x.value_counts().idxmax()\n",
    "}).reset_index()\n",
    "agg_df.to_csv(os.path.join(output_dir, \"character_predictions.csv\"), index=False)\n",
    "\n",
    "# === EVALUATION ===\n",
    "y_true = agg_df[\"true_type\"]\n",
    "y_pred = agg_df[\"predicted_type\"]\n",
    "report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(os.path.join(output_dir, \"character_level_report.csv\"))\n",
    "\n",
    "# === CONFUSION MATRIX ===\n",
    "cm = confusion_matrix(y_true, y_pred, labels=label_encoder.classes_)\n",
    "print(\"\\n📉 Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_))\n",
    "\n",
    "# === PRINT SUMMARY METRICS ===\n",
    "print(\"\\n🏅 Summary (Majority Vote on Sentence Predictions):\")\n",
    "for label in label_encoder.classes_:\n",
    "    p = report[label][\"precision\"]\n",
    "    r = report[label][\"recall\"]\n",
    "    f1 = report[label][\"f1-score\"]\n",
    "    support = report[label][\"support\"]\n",
    "    print(f\"{label:<12}  precision: {p:.4f}  recall: {r:.4f}  f1-score: {f1:.4f}  support: {support:.0f}\")\n",
    "\n",
    "print(f\"\\n✅ Overall Metrics:\")\n",
    "print(f\"accuracy        : {report['accuracy']:.4f}\")\n",
    "print(f\"macro avg f1    : {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"weighted avg f1 : {report['weighted avg']['f1-score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f38855",
   "metadata": {},
   "source": [
    "## cumulative character-level voting across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e6dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Starting Iterative Inference and Voting\n",
      "\n",
      "🔁 Iteration 1\n",
      "\n",
      "🔁 Iteration 2\n",
      "\n",
      "🔁 Iteration 3\n",
      "\n",
      "🔁 Iteration 4\n",
      "\n",
      "🔁 Iteration 5\n",
      "\n",
      "📉 Confusion Matrix (Character-Level Majority Across Iterations):\n",
      "             antagonist  others  protagonist\n",
      "antagonist           24       0            1\n",
      "others                1      98            5\n",
      "protagonist           6       4           52\n",
      "\n",
      "🏅 Summary (Iterative Voting per Character):\n",
      "others        precision: 0.9608  recall: 0.9423  f1-score: 0.9515  support: 104\n",
      "protagonist   precision: 0.8966  recall: 0.8387  f1-score: 0.8667  support: 62\n",
      "antagonist    precision: 0.7742  recall: 0.9600  f1-score: 0.8571  support: 25\n",
      "\n",
      "✅ Overall Metrics:\n",
      "accuracy        : 0.9110\n",
      "macro avg f1    : 0.8918\n",
      "weighted avg f1 : 0.9116\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from safetensors.torch import load_file\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_DIR = \"results/V4_CahyaBERT/best_fold_3\"\n",
    "CSV_PATH = \"sentence_level.csv\"\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ITERATIONS = 5\n",
    "OUTPUT_DIR = \"results/iterative_vote\"\n",
    "LABELS = [\"others\", \"protagonist\", \"antagonist\"]\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === LOAD DATA ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"bert_context_filtered\"] = df[\"bert_context_filtered\"].fillna(\"\")\n",
    "scaler = StandardScaler()\n",
    "df[[\"mention_count\", \"word_count\"]] = scaler.fit_transform(df[[\"mention_count\", \"word_count\"]])\n",
    "numeric_cols = [\"mention_count\", \"word_count\", \"is_primary_in_sentence\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"type\"])\n",
    "\n",
    "# === TOKENIZER ===\n",
    "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert-base-indonesian-1.5G\")\n",
    "\n",
    "# === DATASET ===\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.encodings = tokenizer(df[\"bert_context_filtered\"].tolist(), truncation=True, padding=True, max_length=128)\n",
    "        self.numeric_feats = torch.tensor(df[numeric_cols].values, dtype=torch.float)\n",
    "        self.labels = torch.tensor(df[\"label_encoded\"].values)\n",
    "        self.metadata = df[[\"story_id\", \"person\", \"sentence_id\", \"type\"]].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"numeric_feats\"] = self.numeric_feats[idx]\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        item[\"meta\"] = self.metadata.loc[idx].to_dict()\n",
    "        return item\n",
    "\n",
    "# === COLLATE ===\n",
    "def custom_collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    collated = {k: [d[k] for d in batch] for k in keys}\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"labels\", \"numeric_feats\"]:\n",
    "        collated[k] = torch.stack(collated[k])\n",
    "    return collated\n",
    "\n",
    "# === MODEL ===\n",
    "class IndoBERTWithNumeric(nn.Module):\n",
    "    def __init__(self, model_name=\"cahya/bert-base-indonesian-1.5G\", num_labels=3, num_numeric_features=3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + num_numeric_features, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_feats, labels=None):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        combined = torch.cat((pooled_output, numeric_feats), dim=1)\n",
    "        logits = self.classifier(self.dropout(combined))\n",
    "        return logits\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = IndoBERTWithNumeric()\n",
    "state_dict = load_file(os.path.join(MODEL_DIR, \"model.safetensors\"))\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# === INFERENCE ===\n",
    "dataset = SentenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=custom_collate_fn)\n",
    "\n",
    "predictions_per_sentence = [[] for _ in range(len(df))]\n",
    "\n",
    "print(\"\\n🔁 Starting Iterative Inference and Voting\")\n",
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"\\n🔁 Iteration {iteration + 1}\")\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            numeric_feats = batch[\"numeric_feats\"].to(DEVICE)\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask, numeric_feats=numeric_feats)\n",
    "            preds = torch.argmax(F.softmax(logits, dim=1), dim=1).cpu().numpy()\n",
    "\n",
    "            for p in preds:\n",
    "                predictions_per_sentence[idx].append(p)\n",
    "                idx += 1\n",
    "\n",
    "# === MAJORITY VOTE PER SENTENCE ===\n",
    "final_preds_sentence = [Counter(votes).most_common(1)[0][0] for votes in predictions_per_sentence]\n",
    "df[\"predicted_type_sentence\"] = label_encoder.inverse_transform(final_preds_sentence)\n",
    "\n",
    "# === MAJORITY VOTE PER CHARACTER ===\n",
    "character_votes = defaultdict(list)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    key = (row[\"story_id\"], row[\"person\"])\n",
    "    character_votes[key].append(row[\"predicted_type_sentence\"])\n",
    "\n",
    "character_final_preds = []\n",
    "character_true_labels = []\n",
    "character_ids = []\n",
    "\n",
    "for (story_id, person), votes in character_votes.items():\n",
    "    voted = Counter(votes).most_common(1)[0][0]\n",
    "    true_type = df[(df[\"story_id\"] == story_id) & (df[\"person\"] == person)][\"type\"].mode()[0]\n",
    "    character_ids.append((story_id, person))\n",
    "    character_final_preds.append(voted)\n",
    "    character_true_labels.append(true_type)\n",
    "\n",
    "# === EVALUATION ===\n",
    "y_true = character_true_labels\n",
    "y_pred = character_final_preds\n",
    "\n",
    "report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(os.path.join(OUTPUT_DIR, \"character_level_report_majority_across_iterations.csv\"))\n",
    "\n",
    "# === CONFUSION MATRIX ===\n",
    "cm = confusion_matrix(y_true, y_pred, labels=label_encoder.classes_)\n",
    "print(\"\\n📉 Confusion Matrix (Character-Level Majority Across Iterations):\")\n",
    "print(pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_))\n",
    "\n",
    "# === PRINT METRICS ===\n",
    "print(\"\\n🏅 Summary (Iterative Voting per Character):\")\n",
    "for label in LABELS:\n",
    "    p = report[label][\"precision\"]\n",
    "    r = report[label][\"recall\"]\n",
    "    f1 = report[label][\"f1-score\"]\n",
    "    s = report[label][\"support\"]\n",
    "    print(f\"{label:<12}  precision: {p:.4f}  recall: {r:.4f}  f1-score: {f1:.4f}  support: {int(s)}\")\n",
    "\n",
    "print(f\"\\n✅ Overall Metrics:\")\n",
    "print(f\"accuracy        : {report['accuracy']:.4f}\")\n",
    "print(f\"macro avg f1    : {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"weighted avg f1 : {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# === SAVE PREDICTIONS ===\n",
    "char_pred_df = pd.DataFrame(character_ids, columns=[\"story_id\", \"person\"])\n",
    "char_pred_df[\"true_type\"] = y_true\n",
    "char_pred_df[\"predicted_type\"] = y_pred\n",
    "char_pred_df.to_csv(os.path.join(OUTPUT_DIR, \"character_predictions_majority_across_iterations.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e0ef3",
   "metadata": {},
   "source": [
    "## confidence weigthted vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e46dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Starting Iterative Inference and Confidence-Weighted Voting\n",
      "\n",
      "🔁 Iteration 1\n",
      "\n",
      "🔁 Iteration 2\n",
      "\n",
      "🔁 Iteration 3\n",
      "\n",
      "🔁 Iteration 4\n",
      "\n",
      "🔁 Iteration 5\n",
      "\n",
      "📉 Confusion Matrix (Confidence-Weighted Voting):\n",
      "             antagonist  others  protagonist\n",
      "antagonist            1      24            0\n",
      "others                5       1           98\n",
      "protagonist          53       6            3\n",
      "\n",
      "🏅 Summary (Confidence-Weighted Voting per Character):\n",
      "others        precision: 0.0323  recall: 0.0096  f1-score: 0.0148  support: 104\n",
      "protagonist   precision: 0.0297  recall: 0.0484  f1-score: 0.0368  support: 62\n",
      "antagonist    precision: 0.0169  recall: 0.0400  f1-score: 0.0238  support: 25\n",
      "\n",
      "✅ Overall Metrics:\n",
      "accuracy        : 0.0262\n",
      "macro avg f1    : 0.0251\n",
      "weighted avg f1 : 0.0231\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from safetensors.torch import load_file\n",
    "from collections import defaultdict\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_DIR = \"results/V4_CahyaBERT/best_fold_3\"\n",
    "CSV_PATH = \"sentence_level.csv\"\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ITERATIONS = 5\n",
    "OUTPUT_DIR = \"results/confidence_vote\"\n",
    "LABELS = [\"others\", \"protagonist\", \"antagonist\"]\n",
    "label_to_index = {label: i for i, label in enumerate(LABELS)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === LOAD DATA ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"bert_context_filtered\"] = df[\"bert_context_filtered\"].fillna(\"\")\n",
    "scaler = StandardScaler()\n",
    "df[[\"mention_count\", \"word_count\"]] = scaler.fit_transform(df[[\"mention_count\", \"word_count\"]])\n",
    "numeric_cols = [\"mention_count\", \"word_count\", \"is_primary_in_sentence\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"type\"])\n",
    "\n",
    "# === TOKENIZER ===\n",
    "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert-base-indonesian-1.5G\")\n",
    "\n",
    "# === DATASET ===\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.encodings = tokenizer(df[\"bert_context_filtered\"].tolist(), truncation=True, padding=True, max_length=128)\n",
    "        self.numeric_feats = torch.tensor(df[numeric_cols].values, dtype=torch.float)\n",
    "        self.labels = torch.tensor(df[\"label_encoded\"].values)\n",
    "        self.metadata = df[[\"story_id\", \"person\", \"sentence_id\", \"type\"]].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"numeric_feats\"] = self.numeric_feats[idx]\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        item[\"meta\"] = self.metadata.loc[idx].to_dict()\n",
    "        return item\n",
    "\n",
    "# === COLLATE ===\n",
    "def custom_collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    collated = {k: [d[k] for d in batch] for k in keys}\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"labels\", \"numeric_feats\"]:\n",
    "        collated[k] = torch.stack(collated[k])\n",
    "    return collated\n",
    "\n",
    "# === MODEL ===\n",
    "class IndoBERTWithNumeric(nn.Module):\n",
    "    def __init__(self, model_name=\"cahya/bert-base-indonesian-1.5G\", num_labels=3, num_numeric_features=3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + num_numeric_features, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_feats, labels=None):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        combined = torch.cat((pooled_output, numeric_feats), dim=1)\n",
    "        logits = self.classifier(self.dropout(combined))\n",
    "        return logits\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = IndoBERTWithNumeric()\n",
    "state_dict = load_file(os.path.join(MODEL_DIR, \"model.safetensors\"))\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# === INFERENCE ===\n",
    "dataset = SentenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=custom_collate_fn)\n",
    "\n",
    "# === STORE WEIGHTED CONFIDENCE PER CHARACTER ===\n",
    "character_confidences = defaultdict(lambda: np.zeros(len(LABELS)))\n",
    "character_true_types = {}\n",
    "\n",
    "print(\"\\n🔁 Starting Iterative Inference and Confidence-Weighted Voting\")\n",
    "for iteration in range(ITERATIONS):\n",
    "    print(f\"\\n🔁 Iteration {iteration + 1}\")\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            numeric_feats = batch[\"numeric_feats\"].to(DEVICE)\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask, numeric_feats=numeric_feats)\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "            for i, meta in enumerate(batch[\"meta\"]):\n",
    "                key = (meta[\"story_id\"], meta[\"person\"])\n",
    "                character_confidences[key] += probs[i]\n",
    "                character_true_types[key] = meta[\"type\"]\n",
    "                idx += 1\n",
    "\n",
    "# === FINAL PREDICTIONS ===\n",
    "character_final_preds = []\n",
    "character_true_labels = []\n",
    "character_ids = []\n",
    "\n",
    "for (story_id, person), conf_vector in character_confidences.items():\n",
    "    final_label = index_to_label[np.argmax(conf_vector)]\n",
    "    character_final_preds.append(final_label)\n",
    "    character_true_labels.append(character_true_types[(story_id, person)])\n",
    "    character_ids.append((story_id, person))\n",
    "\n",
    "# === EVALUATION ===\n",
    "y_true = character_true_labels\n",
    "y_pred = character_final_preds\n",
    "report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(os.path.join(OUTPUT_DIR, \"character_level_report_confidence_weighted.csv\"))\n",
    "\n",
    "# === CONFUSION MATRIX ===\n",
    "cm = confusion_matrix(y_true, y_pred, labels=label_encoder.classes_)\n",
    "print(\"\\n📉 Confusion Matrix (Confidence-Weighted Voting):\")\n",
    "print(pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_))\n",
    "\n",
    "# === PRINT METRICS ===\n",
    "print(\"\\n🏅 Summary (Confidence-Weighted Voting per Character):\")\n",
    "for label in LABELS:\n",
    "    p = report[label][\"precision\"]\n",
    "    r = report[label][\"recall\"]\n",
    "    f1 = report[label][\"f1-score\"]\n",
    "    s = report[label][\"support\"]\n",
    "    print(f\"{label:<12}  precision: {p:.4f}  recall: {r:.4f}  f1-score: {f1:.4f}  support: {int(s)}\")\n",
    "\n",
    "print(f\"\\n✅ Overall Metrics:\")\n",
    "print(f\"accuracy        : {report['accuracy']:.4f}\")\n",
    "print(f\"macro avg f1    : {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"weighted avg f1 : {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# === SAVE PREDICTIONS ===\n",
    "char_pred_df = pd.DataFrame(character_ids, columns=[\"story_id\", \"person\"])\n",
    "char_pred_df[\"true_type\"] = y_true\n",
    "char_pred_df[\"predicted_type\"] = y_pred\n",
    "char_pred_df.to_csv(os.path.join(OUTPUT_DIR, \"character_predictions_confidence_weighted.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38788e81",
   "metadata": {},
   "source": [
    "## ensemble voting folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f60b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayssa\\Documents\\nusantara-character-classification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Starting Ensemble Voting Across Folds\n",
      "\n",
      "🔁 Fold 1\n",
      "\n",
      "🔁 Fold 2\n",
      "\n",
      "🔁 Fold 3\n",
      "\n",
      "🔁 Fold 4\n",
      "\n",
      "🔁 Fold 5\n",
      "\n",
      "📉 Confusion Matrix (Character-Level Ensemble Majority):\n",
      "             antagonist  others  protagonist\n",
      "antagonist           22       0            3\n",
      "others                2      96            6\n",
      "protagonist           1       3           58\n",
      "\n",
      "🏅 Summary (Ensemble Voting per Character):\n",
      "others        precision: 0.9697  recall: 0.9231  f1-score: 0.9458  support: 104\n",
      "protagonist   precision: 0.8657  recall: 0.9355  f1-score: 0.8992  support: 62\n",
      "antagonist    precision: 0.8800  recall: 0.8800  f1-score: 0.8800  support: 25\n",
      "\n",
      "✅ Overall Metrics:\n",
      "accuracy        : 0.9215\n",
      "macro avg f1    : 0.9083\n",
      "weighted avg f1 : 0.9221\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from safetensors.torch import load_file\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_MODEL_DIR = \"results/V4_CahyaBERT\"\n",
    "CSV_PATH = \"sentence_level.csv\"\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LABELS = [\"others\", \"protagonist\", \"antagonist\"]\n",
    "OUTPUT_DIR = \"results/ensemble_majority\"\n",
    "FOLDS = 5\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === LOAD DATA ===\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"bert_context_filtered\"] = df[\"bert_context_filtered\"].fillna(\"\")\n",
    "scaler = StandardScaler()\n",
    "df[[\"mention_count\", \"word_count\"]] = scaler.fit_transform(df[[\"mention_count\", \"word_count\"]])\n",
    "numeric_cols = [\"mention_count\", \"word_count\", \"is_primary_in_sentence\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"type\"])\n",
    "\n",
    "# === TOKENIZER ===\n",
    "tokenizer = BertTokenizer.from_pretrained(\"cahya/bert-base-indonesian-1.5G\")\n",
    "\n",
    "# === DATASET ===\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.encodings = tokenizer(df[\"bert_context_filtered\"].tolist(), truncation=True, padding=True, max_length=128)\n",
    "        self.numeric_feats = torch.tensor(df[numeric_cols].values, dtype=torch.float)\n",
    "        self.labels = torch.tensor(df[\"label_encoded\"].values)\n",
    "        self.metadata = df[[\"story_id\", \"person\", \"sentence_id\", \"type\"]].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"numeric_feats\"] = self.numeric_feats[idx]\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        item[\"meta\"] = self.metadata.loc[idx].to_dict()\n",
    "        return item\n",
    "\n",
    "# === COLLATE ===\n",
    "def custom_collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    collated = {k: [d[k] for d in batch] for k in keys}\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"labels\", \"numeric_feats\"]:\n",
    "        collated[k] = torch.stack(collated[k])\n",
    "    return collated\n",
    "\n",
    "# === MODEL ===\n",
    "class IndoBERTWithNumeric(nn.Module):\n",
    "    def __init__(self, model_name=\"cahya/bert-base-indonesian-1.5G\", num_labels=3, num_numeric_features=3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + num_numeric_features, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numeric_feats, labels=None):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        combined = torch.cat((pooled_output, numeric_feats), dim=1)\n",
    "        logits = self.classifier(self.dropout(combined))\n",
    "        return logits\n",
    "\n",
    "# === INFERENCE ACROSS FOLDS ===\n",
    "predictions_per_sentence = [[] for _ in range(len(df))]\n",
    "dataset = SentenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=custom_collate_fn)\n",
    "\n",
    "print(\"\\n🔁 Starting Ensemble Voting Across Folds\")\n",
    "\n",
    "for fold_idx in range(FOLDS):\n",
    "    fold_dir = os.path.join(BASE_MODEL_DIR, f\"best_fold_{fold_idx + 1}\")\n",
    "    print(f\"\\n🔁 Fold {fold_idx + 1}\")\n",
    "    model = IndoBERTWithNumeric()\n",
    "    state_dict = load_file(os.path.join(fold_dir, \"model.safetensors\"))\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            numeric_feats = batch[\"numeric_feats\"].to(DEVICE)\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask, numeric_feats=numeric_feats)\n",
    "            preds = torch.argmax(F.softmax(logits, dim=1), dim=1).cpu().numpy()\n",
    "            for p in preds:\n",
    "                predictions_per_sentence[idx].append(p)\n",
    "                idx += 1\n",
    "\n",
    "# === MAJORITY VOTE PER SENTENCE ===\n",
    "final_preds_sentence = [Counter(votes).most_common(1)[0][0] for votes in predictions_per_sentence]\n",
    "df[\"predicted_type_sentence\"] = label_encoder.inverse_transform(final_preds_sentence)\n",
    "\n",
    "# === MAJORITY VOTE PER CHARACTER ===\n",
    "character_votes = defaultdict(list)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    key = (row[\"story_id\"], row[\"person\"])\n",
    "    character_votes[key].append(row[\"predicted_type_sentence\"])\n",
    "\n",
    "character_final_preds = []\n",
    "character_true_labels = []\n",
    "character_ids = []\n",
    "\n",
    "for (story_id, person), votes in character_votes.items():\n",
    "    voted = Counter(votes).most_common(1)[0][0]\n",
    "    true_type = df[(df[\"story_id\"] == story_id) & (df[\"person\"] == person)][\"type\"].mode()[0]\n",
    "    character_ids.append((story_id, person))\n",
    "    character_final_preds.append(voted)\n",
    "    character_true_labels.append(true_type)\n",
    "\n",
    "# === EVALUATION ===\n",
    "y_true = character_true_labels\n",
    "y_pred = character_final_preds\n",
    "\n",
    "report = classification_report(y_true, y_pred, digits=4, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(os.path.join(OUTPUT_DIR, \"character_level_report_ensemble_majority.csv\"))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=label_encoder.classes_)\n",
    "print(\"\\n📉 Confusion Matrix (Character-Level Ensemble Majority):\")\n",
    "print(pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_))\n",
    "\n",
    "print(\"\\n🏅 Summary (Ensemble Voting per Character):\")\n",
    "for label in LABELS:\n",
    "    p = report[label][\"precision\"]\n",
    "    r = report[label][\"recall\"]\n",
    "    f1 = report[label][\"f1-score\"]\n",
    "    s = report[label][\"support\"]\n",
    "    print(f\"{label:<12}  precision: {p:.4f}  recall: {r:.4f}  f1-score: {f1:.4f}  support: {int(s)}\")\n",
    "\n",
    "print(f\"\\n✅ Overall Metrics:\")\n",
    "print(f\"accuracy        : {report['accuracy']:.4f}\")\n",
    "print(f\"macro avg f1    : {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"weighted avg f1 : {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# === SAVE FINAL CHARACTER-LEVEL PREDICTIONS ===\n",
    "char_pred_df = pd.DataFrame(character_ids, columns=[\"story_id\", \"person\"])\n",
    "char_pred_df[\"true_type\"] = y_true\n",
    "char_pred_df[\"predicted_type\"] = y_pred\n",
    "char_pred_df.to_csv(os.path.join(OUTPUT_DIR, \"character_predictions_ensemble_majority.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6e824d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Macro Precision : 0.9051\n",
      "📌 Macro Recall    : 0.9129\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# === INPUT MANUAL CONFUSION MATRIX (dari hasil ensemble vote) ===\n",
    "# Format: rows = actual, cols = predicted\n",
    "cm = np.array([\n",
    "    [22, 0, 3],     # Actual: antagonist\n",
    "    [2, 96, 6],     # Actual: others\n",
    "    [1, 3, 58]      # Actual: protagonist\n",
    "])\n",
    "\n",
    "# === LABELS ===\n",
    "labels_en = ['antagonist', 'others', 'protagonist']\n",
    "labels_id = ['antagonis', 'lainnya', 'protagonis']\n",
    "\n",
    "# === CONFUSION MATRIX PLOT ===\n",
    "cm_df = pd.DataFrame(cm, index=labels_id, columns=labels_id)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='BuGn')\n",
    "plt.title(\"Confusion Matrix (CahyaBERT V4 - Majority Vote Sentence-Level)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"character_level_confusion_matrix_single_vote.png\")\n",
    "plt.show()\n",
    "\n",
    "# === FLATTEN TO GET TRUE & PRED LABELS ===\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i, actual_class in enumerate(labels_en):\n",
    "    for j, pred_class in enumerate(labels_en):\n",
    "        count = cm[i, j]\n",
    "        y_true.extend([actual_class] * count)\n",
    "        y_pred.extend([pred_class] * count)\n",
    "\n",
    "# === COMPUTE METRICS ===\n",
    "macro_precision = precision_score(y_true, y_pred, labels=labels_en, average='macro')\n",
    "macro_recall = recall_score(y_true, y_pred, labels=labels_en, average='macro')\n",
    "\n",
    "print(f\"📌 Macro Precision : {macro_precision:.4f}\")\n",
    "print(f\"📌 Macro Recall    : {macro_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fba52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
